{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pz0GqMlsD-4_"
   },
   "source": [
    "## Tabular prediciton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "18GbKxxRDzu4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "D5SMTgBuESoe"
   },
   "outputs": [],
   "source": [
    "iris = TabularDataset('sample_data/Iris.csv')\n",
    "df_train, df_test = train_test_split(iris, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "O5ppW7OcFHI9"
   },
   "outputs": [],
   "source": [
    "col = 'Species'\n",
    "y_train = df_train[[col]]\n",
    "X_train = df_train.drop(col,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5P9syYsuF8ht",
    "outputId": "c0f40534-8cd7-44bc-e22e-c083527b7665"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of class variable: \n",
      " count                 105\n",
      "unique                  3\n",
      "top       Iris-versicolor\n",
      "freq                   37\n",
      "Name: Species, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Summary of class variable: \\n\", y_train[col].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fAW83P56GQE8",
    "outputId": "7b9be400-dfa1-453b-feda-0f6272e6289b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"test/agModels-predictClass\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"test/agModels-predictClass\\\"\n",
      "AutoGluon Version:  0.4.0\n",
      "Python Version:     3.9.7\n",
      "Operating System:   Windows\n",
      "Train Data Rows:    105\n",
      "Train Data Columns: 5\n",
      "Label Column: Species\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\t3 unique label values:  ['Iris-versicolor', 'Iris-virginica', 'Iris-setosa']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    8031.7 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.0 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']\n",
      "\t\t('int', [])   : 1 | ['Id']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']\n",
      "\t\t('int', [])   : 1 | ['Id']\n",
      "\t0.0s = Fit runtime\n",
      "\t5 features in original data used to generate 5 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.0 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.05s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 84, Val Rows: 21\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "No improvement since epoch 5: early stopping\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t2.55s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.8s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.13s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.39s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.31s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.8s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.32s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.32s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.9524\t = Validation score   (accuracy)\n",
      "\t0.58s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.71s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.22s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.2s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 7.98s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"test/agModels-predictClass\\\")\n"
     ]
    }
   ],
   "source": [
    "save_path = 'test/agModels-predictClass' \n",
    "predictor = TabularPredictor(label=col, path=save_path).fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Lylckic3G0X3",
    "outputId": "c921c880-33cb-4029-f0bd-37139975d1cc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>74</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>119</td>\n",
       "      <td>7.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>79</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>77</td>\n",
       "      <td>6.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm\n",
       "73    74            6.1           2.8            4.7           1.2\n",
       "18    19            5.7           3.8            1.7           0.3\n",
       "118  119            7.7           2.6            6.9           2.3\n",
       "78    79            6.0           2.9            4.5           1.5\n",
       "76    77            6.8           2.8            4.8           1.4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = df_test\n",
    "y_test = test_data[col] \n",
    "test_data_nolab = test_data.drop(columns=[col]) \n",
    "test_data_nolab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zfOUQb83HK97",
    "outputId": "b055b2dc-48d1-4f22-a9af-abc695aa34a8",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: accuracy on test data: 1.0\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"accuracy\": 1.0,\n",
      "    \"balanced_accuracy\": 1.0,\n",
      "    \"mcc\": 1.0\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:  \n",
      " 73     Iris-versicolor\n",
      "18         Iris-setosa\n",
      "118     Iris-virginica\n",
      "78     Iris-versicolor\n",
      "76     Iris-versicolor\n",
      "31         Iris-setosa\n",
      "64     Iris-versicolor\n",
      "141     Iris-virginica\n",
      "68     Iris-versicolor\n",
      "82     Iris-versicolor\n",
      "110     Iris-virginica\n",
      "12         Iris-setosa\n",
      "36         Iris-setosa\n",
      "9          Iris-setosa\n",
      "19         Iris-setosa\n",
      "56     Iris-versicolor\n",
      "104     Iris-virginica\n",
      "69     Iris-versicolor\n",
      "55     Iris-versicolor\n",
      "132     Iris-virginica\n",
      "29         Iris-setosa\n",
      "127     Iris-virginica\n",
      "26         Iris-setosa\n",
      "128     Iris-virginica\n",
      "131     Iris-virginica\n",
      "145     Iris-virginica\n",
      "108     Iris-virginica\n",
      "143     Iris-virginica\n",
      "45         Iris-setosa\n",
      "30         Iris-setosa\n",
      "22         Iris-setosa\n",
      "15         Iris-setosa\n",
      "65     Iris-versicolor\n",
      "11         Iris-setosa\n",
      "42         Iris-setosa\n",
      "146     Iris-virginica\n",
      "51     Iris-versicolor\n",
      "27         Iris-setosa\n",
      "4          Iris-setosa\n",
      "32         Iris-setosa\n",
      "142     Iris-virginica\n",
      "85     Iris-versicolor\n",
      "86     Iris-versicolor\n",
      "16         Iris-setosa\n",
      "10         Iris-setosa\n",
      "Name: Species, dtype: object\n"
     ]
    }
   ],
   "source": [
    "y_pred = predictor.predict(test_data_nolab)\n",
    "print(\"Predictions:  \\n\", y_pred)\n",
    "perf = predictor.evaluate_predictions(y_true=y_test, y_pred=y_pred, auxiliary_metrics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 553
    },
    "id": "QuYH-jfzHSxs",
    "outputId": "9557b45e-ac1d-46a2-d727-1a808b4d9136"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001501</td>\n",
       "      <td>0.003002</td>\n",
       "      <td>0.215185</td>\n",
       "      <td>0.001501</td>\n",
       "      <td>0.003002</td>\n",
       "      <td>0.215185</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001502</td>\n",
       "      <td>0.002001</td>\n",
       "      <td>0.804509</td>\n",
       "      <td>0.001502</td>\n",
       "      <td>0.002001</td>\n",
       "      <td>0.804509</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002002</td>\n",
       "      <td>0.002502</td>\n",
       "      <td>0.126609</td>\n",
       "      <td>0.002002</td>\n",
       "      <td>0.002502</td>\n",
       "      <td>0.126609</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002502</td>\n",
       "      <td>0.002502</td>\n",
       "      <td>0.795886</td>\n",
       "      <td>0.002502</td>\n",
       "      <td>0.002502</td>\n",
       "      <td>0.795886</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.006005</td>\n",
       "      <td>0.006005</td>\n",
       "      <td>0.575802</td>\n",
       "      <td>0.006005</td>\n",
       "      <td>0.006005</td>\n",
       "      <td>0.575802</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNeighborsUnif</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.006505</td>\n",
       "      <td>0.009509</td>\n",
       "      <td>0.006506</td>\n",
       "      <td>0.006505</td>\n",
       "      <td>0.009509</td>\n",
       "      <td>0.006506</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NeuralNetTorch</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.007506</td>\n",
       "      <td>0.003504</td>\n",
       "      <td>0.713613</td>\n",
       "      <td>0.007506</td>\n",
       "      <td>0.003504</td>\n",
       "      <td>0.713613</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNeighborsDist</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.008007</td>\n",
       "      <td>0.007507</td>\n",
       "      <td>0.003502</td>\n",
       "      <td>0.008007</td>\n",
       "      <td>0.007507</td>\n",
       "      <td>0.003502</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ExtraTreesGini</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.037532</td>\n",
       "      <td>0.031026</td>\n",
       "      <td>0.323279</td>\n",
       "      <td>0.037532</td>\n",
       "      <td>0.031026</td>\n",
       "      <td>0.323279</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesEntr</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.038533</td>\n",
       "      <td>0.027025</td>\n",
       "      <td>0.317772</td>\n",
       "      <td>0.038533</td>\n",
       "      <td>0.027025</td>\n",
       "      <td>0.317772</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RandomForestGini</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.045039</td>\n",
       "      <td>0.029026</td>\n",
       "      <td>0.392337</td>\n",
       "      <td>0.045039</td>\n",
       "      <td>0.029026</td>\n",
       "      <td>0.392337</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.048041</td>\n",
       "      <td>0.029026</td>\n",
       "      <td>0.595512</td>\n",
       "      <td>0.003003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.203175</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RandomForestEntr</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.051044</td>\n",
       "      <td>0.028525</td>\n",
       "      <td>0.309766</td>\n",
       "      <td>0.051044</td>\n",
       "      <td>0.028525</td>\n",
       "      <td>0.309766</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.015013</td>\n",
       "      <td>0.010009</td>\n",
       "      <td>2.545530</td>\n",
       "      <td>0.015013</td>\n",
       "      <td>0.010009</td>\n",
       "      <td>2.545530</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  score_test  score_val  pred_time_test  pred_time_val  \\\n",
       "0         LightGBMLarge    1.000000   1.000000        0.001501       0.003002   \n",
       "1              CatBoost    1.000000   1.000000        0.001502       0.002001   \n",
       "2              LightGBM    1.000000   1.000000        0.002002       0.002502   \n",
       "3            LightGBMXT    1.000000   1.000000        0.002502       0.002502   \n",
       "4               XGBoost    1.000000   0.952381        0.006005       0.006005   \n",
       "5        KNeighborsUnif    1.000000   1.000000        0.006505       0.009509   \n",
       "6        NeuralNetTorch    1.000000   1.000000        0.007506       0.003504   \n",
       "7        KNeighborsDist    1.000000   1.000000        0.008007       0.007507   \n",
       "8        ExtraTreesGini    1.000000   1.000000        0.037532       0.031026   \n",
       "9        ExtraTreesEntr    1.000000   1.000000        0.038533       0.027025   \n",
       "10     RandomForestGini    1.000000   1.000000        0.045039       0.029026   \n",
       "11  WeightedEnsemble_L2    1.000000   1.000000        0.048041       0.029026   \n",
       "12     RandomForestEntr    1.000000   1.000000        0.051044       0.028525   \n",
       "13      NeuralNetFastAI    0.977778   1.000000        0.015013       0.010009   \n",
       "\n",
       "    fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0   0.215185                 0.001501                0.003002   \n",
       "1   0.804509                 0.001502                0.002001   \n",
       "2   0.126609                 0.002002                0.002502   \n",
       "3   0.795886                 0.002502                0.002502   \n",
       "4   0.575802                 0.006005                0.006005   \n",
       "5   0.006506                 0.006505                0.009509   \n",
       "6   0.713613                 0.007506                0.003504   \n",
       "7   0.003502                 0.008007                0.007507   \n",
       "8   0.323279                 0.037532                0.031026   \n",
       "9   0.317772                 0.038533                0.027025   \n",
       "10  0.392337                 0.045039                0.029026   \n",
       "11  0.595512                 0.003003                0.000000   \n",
       "12  0.309766                 0.051044                0.028525   \n",
       "13  2.545530                 0.015013                0.010009   \n",
       "\n",
       "    fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0            0.215185            1       True         13  \n",
       "1            0.804509            1       True          8  \n",
       "2            0.126609            1       True          5  \n",
       "3            0.795886            1       True          4  \n",
       "4            0.575802            1       True         11  \n",
       "5            0.006506            1       True          1  \n",
       "6            0.713613            1       True         12  \n",
       "7            0.003502            1       True          2  \n",
       "8            0.323279            1       True          9  \n",
       "9            0.317772            1       True         10  \n",
       "10           0.392337            1       True          6  \n",
       "11           0.203175            2       True         14  \n",
       "12           0.309766            1       True          7  \n",
       "13           2.545530            1       True          3  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(test_data, silent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JgPdGVNyL4zz"
   },
   "source": [
    "## Metoda .fit()\n",
    "AutoGluon:\n",
    "* automatycznie określa typ każdej zmiennej (tj. które kolumny zawierają zmienne ciągłe w porównaniu ze zmiennymi dyskretnymi).\n",
    "\n",
    "* automatycznie obsługuje również typowe problemy, takie jak np. braki danych oraz przeskalowywanie wartości poszczególnych zmiennych.\n",
    "\n",
    "* automatycznie wybiera losowy podział danych odpowiednio na zbiór treningowy oraz walidacyjny. Dane używane do walidacji są oddzielone od danych ze zbioru treningowego i są potrzebne do określenia modeli jak i wartości hiperparametrów, w celu uzyskania jak najlepszych wyników.\n",
    "\n",
    "* Zamiast pojedynczego modelu, AutoGluon szkoli wiele modeli po czym łączy je ze sobą w całość, by zapewnić doskonałą wydajność predykcyjną. \n",
    "\n",
    "* Automatyzuje proces hiperparametryzacji poszczególnych modeli -- które użytkownik musiałby wcześniej określić"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3xsK4JJ8RHuR"
   },
   "source": [
    "W przypadku problemów tabularycznych .fit() zwraca obiekt Predictor.\n",
    "Natomiast w przypadku klasyfikacji można łatwo wyprowadzić przewidywane prawdopodobieństwa klas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "tomYbq0FRxJ-",
    "outputId": "9d736256-d913-475a-fe1e-5cfa6357e7ec"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iris-setosa</th>\n",
       "      <th>Iris-versicolor</th>\n",
       "      <th>Iris-virginica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.956667</td>\n",
       "      <td>0.043333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.996667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.040000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Iris-setosa  Iris-versicolor  Iris-virginica\n",
       "73      0.000000         1.000000        0.000000\n",
       "18      0.956667         0.043333        0.000000\n",
       "118     0.000000         0.003333        0.996667\n",
       "78      0.000000         0.990000        0.010000\n",
       "76      0.000000         0.960000        0.040000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_probs = predictor.predict_proba(test_data_nolab)\n",
    "pred_probs.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7JLja3GdR6S-",
    "outputId": "e010bbdd-f19a-4f11-80ec-d7ce171564fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                  model  score_val  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0              CatBoost   1.000000       0.002001  0.804509                0.002001           0.804509            1       True          8\n",
      "1              LightGBM   1.000000       0.002502  0.126609                0.002502           0.126609            1       True          5\n",
      "2            LightGBMXT   1.000000       0.002502  0.795886                0.002502           0.795886            1       True          4\n",
      "3         LightGBMLarge   1.000000       0.003002  0.215185                0.003002           0.215185            1       True         13\n",
      "4        NeuralNetTorch   1.000000       0.003504  0.713613                0.003504           0.713613            1       True         12\n",
      "5        KNeighborsDist   1.000000       0.007507  0.003502                0.007507           0.003502            1       True          2\n",
      "6        KNeighborsUnif   1.000000       0.009509  0.006506                0.009509           0.006506            1       True          1\n",
      "7       NeuralNetFastAI   1.000000       0.010009  2.545530                0.010009           2.545530            1       True          3\n",
      "8        ExtraTreesEntr   1.000000       0.027025  0.317772                0.027025           0.317772            1       True         10\n",
      "9      RandomForestEntr   1.000000       0.028525  0.309766                0.028525           0.309766            1       True          7\n",
      "10  WeightedEnsemble_L2   1.000000       0.029026  0.595512                0.000000           0.203175            2       True         14\n",
      "11     RandomForestGini   1.000000       0.029026  0.392337                0.029026           0.392337            1       True          6\n",
      "12       ExtraTreesGini   1.000000       0.031026  0.323279                0.031026           0.323279            1       True          9\n",
      "13              XGBoost   0.952381       0.006005  0.575802                0.006005           0.575802            1       True         11\n",
      "Number of models trained: 14\n",
      "Types of models trained:\n",
      "{'XTModel', 'NNFastAiTabularModel', 'TabularNeuralNetTorchModel', 'CatBoostModel', 'WeightedEnsembleModel', 'RFModel', 'XGBoostModel', 'LGBModel', 'KNNModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('float', []) : 4 | ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']\n",
      "('int', [])   : 1 | ['Id']\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikol\\AppData\\Roaming\\Python\\Python39\\site-packages\\autogluon\\core\\utils\\plots.py:138: UserWarning: AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"\n",
      "  warnings.warn('AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"')\n"
     ]
    }
   ],
   "source": [
    "results = predictor.fit_summary(show_plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J4JD-U51R-0W"
   },
   "source": [
    "Z podsumowania widać, że nasz ulubieniec wyszkolił wiele różnych modeli:\n",
    "`KNNModel`, `WeightedEnsembleModel`, `TabularNeuralNetTorchModel`, `CatBoostModel`, `XGBoostModel`, `XTModel`, `NNFastAiTabularModel`, `LGBModel`, `RFModel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TUD4X6gCL8fC",
    "outputId": "738c80ec-b556-4113-c278-f5fd4c6c4160"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoGluon infers problem type is:  multiclass\n",
      "AutoGluon identified the following types of features:\n",
      "('float', []) : 4 | ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']\n",
      "('int', [])   : 1 | ['Id']\n"
     ]
    }
   ],
   "source": [
    "print(\"AutoGluon infers problem type is: \", predictor.problem_type)\n",
    "print(\"AutoGluon identified the following types of features:\")\n",
    "print(predictor.feature_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mrxCgKNhPnMP"
   },
   "source": [
    "Jak widzimy, Autogluon poprawnie wykrył typy danych jak również postawiony problem jakim był `multiclass`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6eFIxICXS1q-"
   },
   "source": [
    "Możemy ocenić wydajność każdego indywidualnego wytrenowanego modelu na naszych (oznaczonych) danych testowych:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 553
    },
    "id": "IJOyA_XzPtW-",
    "outputId": "b4e16b66-f3d6-46bd-c8cf-63bcf2ab75cd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.002502</td>\n",
       "      <td>0.126609</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.002502</td>\n",
       "      <td>0.126609</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001501</td>\n",
       "      <td>0.003002</td>\n",
       "      <td>0.215185</td>\n",
       "      <td>0.001501</td>\n",
       "      <td>0.003002</td>\n",
       "      <td>0.215185</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001501</td>\n",
       "      <td>0.002001</td>\n",
       "      <td>0.804509</td>\n",
       "      <td>0.001501</td>\n",
       "      <td>0.002001</td>\n",
       "      <td>0.804509</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002502</td>\n",
       "      <td>0.002502</td>\n",
       "      <td>0.795886</td>\n",
       "      <td>0.002502</td>\n",
       "      <td>0.002502</td>\n",
       "      <td>0.795886</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.005005</td>\n",
       "      <td>0.006005</td>\n",
       "      <td>0.575802</td>\n",
       "      <td>0.005005</td>\n",
       "      <td>0.006005</td>\n",
       "      <td>0.575802</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NeuralNetTorch</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.006005</td>\n",
       "      <td>0.003504</td>\n",
       "      <td>0.713613</td>\n",
       "      <td>0.006005</td>\n",
       "      <td>0.003504</td>\n",
       "      <td>0.713613</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNeighborsUnif</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.006006</td>\n",
       "      <td>0.009509</td>\n",
       "      <td>0.006506</td>\n",
       "      <td>0.006006</td>\n",
       "      <td>0.009509</td>\n",
       "      <td>0.006506</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNeighborsDist</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.007007</td>\n",
       "      <td>0.007507</td>\n",
       "      <td>0.003502</td>\n",
       "      <td>0.007007</td>\n",
       "      <td>0.007507</td>\n",
       "      <td>0.003502</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ExtraTreesEntr</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.037532</td>\n",
       "      <td>0.027025</td>\n",
       "      <td>0.317772</td>\n",
       "      <td>0.037532</td>\n",
       "      <td>0.027025</td>\n",
       "      <td>0.317772</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesGini</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.037533</td>\n",
       "      <td>0.031026</td>\n",
       "      <td>0.323279</td>\n",
       "      <td>0.037533</td>\n",
       "      <td>0.031026</td>\n",
       "      <td>0.323279</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RandomForestGini</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.044038</td>\n",
       "      <td>0.029026</td>\n",
       "      <td>0.392337</td>\n",
       "      <td>0.044038</td>\n",
       "      <td>0.029026</td>\n",
       "      <td>0.392337</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.045539</td>\n",
       "      <td>0.029026</td>\n",
       "      <td>0.595512</td>\n",
       "      <td>0.001501</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.203175</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RandomForestEntr</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.047541</td>\n",
       "      <td>0.028525</td>\n",
       "      <td>0.309766</td>\n",
       "      <td>0.047541</td>\n",
       "      <td>0.028525</td>\n",
       "      <td>0.309766</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.011010</td>\n",
       "      <td>0.010009</td>\n",
       "      <td>2.545530</td>\n",
       "      <td>0.011010</td>\n",
       "      <td>0.010009</td>\n",
       "      <td>2.545530</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  score_test  score_val  pred_time_test  pred_time_val  \\\n",
       "0              LightGBM    1.000000   1.000000        0.001500       0.002502   \n",
       "1         LightGBMLarge    1.000000   1.000000        0.001501       0.003002   \n",
       "2              CatBoost    1.000000   1.000000        0.001501       0.002001   \n",
       "3            LightGBMXT    1.000000   1.000000        0.002502       0.002502   \n",
       "4               XGBoost    1.000000   0.952381        0.005005       0.006005   \n",
       "5        NeuralNetTorch    1.000000   1.000000        0.006005       0.003504   \n",
       "6        KNeighborsUnif    1.000000   1.000000        0.006006       0.009509   \n",
       "7        KNeighborsDist    1.000000   1.000000        0.007007       0.007507   \n",
       "8        ExtraTreesEntr    1.000000   1.000000        0.037532       0.027025   \n",
       "9        ExtraTreesGini    1.000000   1.000000        0.037533       0.031026   \n",
       "10     RandomForestGini    1.000000   1.000000        0.044038       0.029026   \n",
       "11  WeightedEnsemble_L2    1.000000   1.000000        0.045539       0.029026   \n",
       "12     RandomForestEntr    1.000000   1.000000        0.047541       0.028525   \n",
       "13      NeuralNetFastAI    0.977778   1.000000        0.011010       0.010009   \n",
       "\n",
       "    fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0   0.126609                 0.001500                0.002502   \n",
       "1   0.215185                 0.001501                0.003002   \n",
       "2   0.804509                 0.001501                0.002001   \n",
       "3   0.795886                 0.002502                0.002502   \n",
       "4   0.575802                 0.005005                0.006005   \n",
       "5   0.713613                 0.006005                0.003504   \n",
       "6   0.006506                 0.006006                0.009509   \n",
       "7   0.003502                 0.007007                0.007507   \n",
       "8   0.317772                 0.037532                0.027025   \n",
       "9   0.323279                 0.037533                0.031026   \n",
       "10  0.392337                 0.044038                0.029026   \n",
       "11  0.595512                 0.001501                0.000000   \n",
       "12  0.309766                 0.047541                0.028525   \n",
       "13  2.545530                 0.011010                0.010009   \n",
       "\n",
       "    fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0            0.126609            1       True          5  \n",
       "1            0.215185            1       True         13  \n",
       "2            0.804509            1       True          8  \n",
       "3            0.795886            1       True          4  \n",
       "4            0.575802            1       True         11  \n",
       "5            0.713613            1       True         12  \n",
       "6            0.006506            1       True          1  \n",
       "7            0.003502            1       True          2  \n",
       "8            0.317772            1       True         10  \n",
       "9            0.323279            1       True          9  \n",
       "10           0.392337            1       True          6  \n",
       "11           0.203175            2       True         14  \n",
       "12           0.309766            1       True          7  \n",
       "13           2.545530            1       True          3  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(test_data, silent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kpfcGDJATK0r"
   },
   "source": [
    "## Presets\n",
    "Autogluon oferuje 4 rodzaje ustawienia metody .fit()\n",
    "`best_quality`, `high_quality`, `good_quality`, `medium_quality`.\n",
    "\n",
    "`medium_quality` jest domyślnie używaną opcją. Każda z pozostałych opcji wymaga więcej ilości pamięci oraz jej wywołanie zajmuje dużo więcej czasu, dlatego zalecane jest stopniowe zmienianie presetów w celu poprawnej ewaulacji i określenia czy nasz model jest w stanie się nauczyć na określonym przedziale czasowym."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kXsE9jwCrjNP"
   },
   "source": [
    "## Poprawianie wydajności domyślnych parametrów"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KgsO16UCrjNQ"
   },
   "source": [
    "1. Test na defaultowych wartościach\n",
    "2. Próba modyfikacji TabularPredictor(eval_metric = ...) oraz fit(presets = ...)\n",
    "3. Modyfikacja argumentów funkcji fit(), tj. hyperparameter_tune_kwargs, hyperparameters, num_stack_levels, num_bag_folds, num_bag_sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "qATMiasJrjNQ",
    "outputId": "31e2154f-d72a-4826-f662-ac205b6534bf",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: https://autogluon.s3.amazonaws.com/datasets/Inc/train.csv | Columns = 15 / 15 | Rows = 39073 -> 39073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       age workclass  fnlwgt      education  education-num  \\\n",
      "6118    51   Private   39264   Some-college             10   \n",
      "23204   58   Private   51662           10th              6   \n",
      "29590   40   Private  326310   Some-college             10   \n",
      "18116   37   Private  222450        HS-grad              9   \n",
      "33964   62   Private  109190      Bachelors             13   \n",
      "\n",
      "            marital-status        occupation    relationship    race      sex  \\\n",
      "6118    Married-civ-spouse   Exec-managerial            Wife   White   Female   \n",
      "23204   Married-civ-spouse     Other-service            Wife   White   Female   \n",
      "29590   Married-civ-spouse      Craft-repair         Husband   White     Male   \n",
      "18116        Never-married             Sales   Not-in-family   White     Male   \n",
      "33964   Married-civ-spouse   Exec-managerial         Husband   White     Male   \n",
      "\n",
      "       capital-gain  capital-loss  hours-per-week  native-country   class  \n",
      "6118              0             0              40   United-States    >50K  \n",
      "23204             0             0               8   United-States   <=50K  \n",
      "29590             0             0              44   United-States   <=50K  \n",
      "18116             0          2339              40     El-Salvador   <=50K  \n",
      "33964         15024             0              40   United-States    >50K  \n",
      "Summary of occupation column: \n",
      " count                  500\n",
      "unique                  15\n",
      "top        Exec-managerial\n",
      "freq                    77\n",
      "Name: occupation, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: https://autogluon.s3.amazonaws.com/datasets/Inc/test.csv | Columns = 15 / 15 | Rows = 9769 -> 9769\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "train_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/Inc/train.csv')\n",
    "subsample_size = 500  # dla dema 500, normalnie powinnismy uzyc duzo wiekszej wartosci\n",
    "train_data = train_data.sample(n=subsample_size, random_state=0)\n",
    "print(train_data.head())\n",
    "\n",
    "label = 'occupation'\n",
    "print(\"Summary of occupation column: \\n\", train_data['occupation'].describe())\n",
    "\n",
    "new_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/Inc/test.csv')\n",
    "test_data = new_data[5000:].copy()  \n",
    "y_test = test_data[label]\n",
    "test_data_nolabel = test_data.drop(columns=[label]) \n",
    "val_data = new_data[:5000].copy()\n",
    "\n",
    "metric = 'accuracy' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l84B33EkrjNR"
   },
   "source": [
    "**Optymalizacja hiperparametrów**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GNq33y1yrjNR"
   },
   "source": [
    "Jeśli nie masz silnego powodu, aby podać własny zestaw danych do walidacji, zalecamy pominięcie argumentu `tuning_data`. Dzięki temu AutoGluon automatycznie wybiera dane walidacyjne z dostarczonego zestawu treningowego (wykorzystuje inteligentne strategie, takie jak próbkowanie warstwowe (stratified sampling)).\n",
    "\n",
    "Argument `holdout_frac` pozwala określić jaka część danych testowych ma być przeznaczona na walidacyjny zbiór danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "5a35c319b89a4d019f3a432cc3c06b66",
      "d61cc9cea25e4ade980b9129ea6f4507"
     ]
    },
    "id": "saryynLfrjNR",
    "outputId": "a3f735a9-7324-4635-c078-74fa350ea04b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20220406_182811\\\"\n",
      "Warning: hyperparameter tuning is currently experimental and may cause the process to hang.\n",
      "Beginning AutoGluon training ... Time limit = 120s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20220406_182811\\\"\n",
      "AutoGluon Version:  0.4.0\n",
      "Python Version:     3.9.7\n",
      "Operating System:   Windows\n",
      "Train Data Rows:    500\n",
      "Train Data Columns: 14\n",
      "Tuning Data Rows:    5000\n",
      "Tuning Data Columns: 14\n",
      "Label Column: occupation\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\tFirst 10 (of 15) unique label values:  [' Exec-managerial', ' Other-service', ' Craft-repair', ' Sales', ' Prof-specialty', ' Protective-serv', ' ?', ' Adm-clerical', ' Machine-op-inspct', ' Tech-support']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 12 out of 15 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.978\n",
      "Train Data Class Count: 12\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    7844.32 MB\n",
      "\tTrain Data (Original)  Memory Usage: 3.11 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'relationship', 'race', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 6 | ['workclass', 'education', 'marital-status', 'relationship', 'race', ...]\n",
      "\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('int', ['bool']) : 2 | ['sex', 'class']\n",
      "\t0.1s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.3 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.12s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Fitting 2 L1 models ...\n",
      "Hyperparameter tuning model: LightGBM ... Tuning model for up to 53.95s of the 119.88s of remaining time.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b634dd2165a54cf6a55fe2096ea14f82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitted model: LightGBM\\T1 ...\n",
      "\t0.3033\t = Validation score   (accuracy)\n",
      "\t0.64s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitted model: LightGBM\\T2 ...\n",
      "\t0.2899\t = Validation score   (accuracy)\n",
      "\t0.8s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitted model: LightGBM\\T3 ...\n",
      "\t0.3238\t = Validation score   (accuracy)\n",
      "\t0.39s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitted model: LightGBM\\T4 ...\n",
      "\t0.2809\t = Validation score   (accuracy)\n",
      "\t0.75s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitted model: LightGBM\\T5 ...\n",
      "\t0.3108\t = Validation score   (accuracy)\n",
      "\t0.85s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Hyperparameter tuning model: NeuralNetTorch ... Tuning model for up to 53.95s of the 115.83s of remaining time.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8a2810bf0cc4551b8ebd248878a05eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitted model: NeuralNetTorch\\T1 ...\n",
      "\t0.2557\t = Validation score   (accuracy)\n",
      "\t1.33s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitted model: NeuralNetTorch\\T2 ...\n",
      "\t0.3184\t = Validation score   (accuracy)\n",
      "\t1.59s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitted model: NeuralNetTorch\\T3 ...\n",
      "\t0.3236\t = Validation score   (accuracy)\n",
      "\t1.7s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitted model: NeuralNetTorch\\T4 ...\n",
      "\t0.326\t = Validation score   (accuracy)\n",
      "\t2.58s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitted model: NeuralNetTorch\\T5 ...\n",
      "\t0.3342\t = Validation score   (accuracy)\n",
      "\t3.16s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 119.88s of the 103.6s of remaining time.\n",
      "\t0.3547\t = Validation score   (accuracy)\n",
      "\t0.85s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 17.28s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220406_182811\\\")\n"
     ]
    }
   ],
   "source": [
    "import autogluon.core as ag\n",
    "\n",
    "nn_options = {  \n",
    "    'num_epochs': 10,  \n",
    "    'learning_rate': ag.space.Real(1e-4, 1e-2, default=5e-4, log=True), \n",
    "    'activation': ag.space.Categorical('relu', 'softrelu', 'tanh'),  \n",
    "    'dropout_prob': ag.space.Real(0.0, 0.5, default=0.1), \n",
    "}\n",
    "\n",
    "gbm_options = {  \n",
    "    'num_boost_round': 100, \n",
    "    'num_leaves': ag.space.Int(lower=26, upper=66, default=36),  \n",
    "}\n",
    "\n",
    "hyperparameters = {  \n",
    "                   'GBM': gbm_options,\n",
    "                   'NN_TORCH': nn_options, \n",
    "                  }  \n",
    "\n",
    "time_limit = 2*60 \n",
    "num_trials = 5  #  5 prób różnych hiperparametrów dla każdego modelu\n",
    "search_strategy = 'auto'  # aktualnie tylko randomSearch\n",
    "\n",
    "hyperparameter_tune_kwargs = {\n",
    "    'num_trials': num_trials,\n",
    "    'scheduler' : 'local',\n",
    "    'searcher': search_strategy,\n",
    "}\n",
    "\n",
    "predictor = TabularPredictor(label=label, eval_metric=metric).fit(\n",
    "    train_data, tuning_data=val_data, time_limit=time_limit,\n",
    "    hyperparameters=hyperparameters, hyperparameter_tune_kwargs=hyperparameter_tune_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "79TvNOqmrjNR",
    "outputId": "6373f63e-b5c0-4e49-82c0-23989eb31980",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:   [' Exec-managerial', ' Exec-managerial', ' Craft-repair', ' Other-service', ' Adm-clerical']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: accuracy on test data: 0.33088697840218073\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"accuracy\": 0.33088697840218073\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "y_pred = predictor.predict(test_data_nolabel)\n",
    "print(\"Predictions:  \", list(y_pred)[:5])\n",
    "perf = predictor.evaluate(test_data, auxiliary_metrics=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "anFnScQVrjNS"
   },
   "source": [
    "**Podsumowanie modeli**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "iqePleB6rjNS",
    "outputId": "39cda235-75c4-40f9-8ff8-10911b8716cd",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                  model  score_val  pred_time_val   fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0   WeightedEnsemble_L2   0.354726       0.845227  14.648582                0.001503           0.849730            2       True         11\n",
      "1     NeuralNetTorch\\T5   0.334222       0.159637   3.164719                0.159637           3.164719            1       True         10\n",
      "2     NeuralNetTorch\\T4   0.326020       0.150629   2.578715                0.150629           2.578715            1       True          9\n",
      "3           LightGBM\\T3   0.323765       0.017514   0.393338                0.017514           0.393338            1       True          3\n",
      "4     NeuralNetTorch\\T3   0.323560       0.106092   1.697458                0.106092           1.697458            1       True          8\n",
      "5     NeuralNetTorch\\T2   0.318433       0.114098   1.589865                0.114098           1.589865            1       True          7\n",
      "6           LightGBM\\T5   0.310847       0.030526   0.850731                0.030526           0.850731            1       True          5\n",
      "7           LightGBM\\T1   0.303260       0.048541   0.638548                0.048541           0.638548            1       True          1\n",
      "8           LightGBM\\T2   0.289932       0.043037   0.803190                0.043037           0.803190            1       True          2\n",
      "9           LightGBM\\T4   0.280910       0.085074   0.754648                0.085074           0.754648            1       True          4\n",
      "10    NeuralNetTorch\\T1   0.255690       0.088576   1.327640                0.088576           1.327640            1       True          6\n",
      "Number of models trained: 11\n",
      "Types of models trained:\n",
      "{'TabularNeuralNetTorchModel', 'WeightedEnsembleModel', 'LGBModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', [])  : 6 | ['workclass', 'education', 'marital-status', 'relationship', 'race', ...]\n",
      "('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "('int', ['bool']) : 2 | ['sex', 'class']\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikol\\AppData\\Roaming\\Python\\Python39\\site-packages\\autogluon\\core\\utils\\plots.py:138: UserWarning: AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"\n",
      "  warnings.warn('AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"')\n"
     ]
    }
   ],
   "source": [
    "results = predictor.fit_summary(show_plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H2sL8gdurjNS"
   },
   "source": [
    "W powyższym przykładzie predykcyjność może być słaba ze względu na bardzo małą ilość `triali`. Aby zwiększyć predykcyjność i lepiej zrozumieć jak dane hiperparametry wpływają na predykcyjność moglibyśmy zmodyfikować powyższe hiperparametry (szczególnie `num_epochs`, `num_boost_round` oraz `time_limit`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EXbNkc42rjNS"
   },
   "source": [
    "## Model ensembling with stacking/bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fTzeMkpSrjNS"
   },
   "source": [
    "Często zauważymy poprawę wydajności modelu, jeśli określimy `num_bag_folds = 5-10`, `num_stack_levels = 1-3` w wywołaniu fit(), lecz wydłuży to czas trenowania i zużycie pamięci/dysku. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "vD15lDjDrjNS",
    "outputId": "d3cbfd40-fb26-43ce-c956-e818efcbb21f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20220406_182830\\\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20220406_182830\\\"\n",
      "AutoGluon Version:  0.4.0\n",
      "Python Version:     3.9.7\n",
      "Operating System:   Windows\n",
      "Train Data Rows:    500\n",
      "Train Data Columns: 14\n",
      "Label Column: occupation\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\tFirst 10 (of 15) unique label values:  [' Exec-managerial', ' Other-service', ' Craft-repair', ' Sales', ' Prof-specialty', ' Protective-serv', ' ?', ' Adm-clerical', ' Machine-op-inspct', ' Tech-support']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 12 out of 15 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.978\n",
      "Train Data Class Count: 12\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    7818.49 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.28 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'relationship', 'race', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 6 | ['workclass', 'education', 'marital-status', 'relationship', 'race', ...]\n",
      "\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('int', ['bool']) : 2 | ['sex', 'class']\n",
      "\t0.1s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.09s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 2 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.3067\t = Validation score   (accuracy)\n",
      "\t1.12s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ...\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1656\t = Validation score   (accuracy)\n",
      "\t0.81s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.3067\t = Validation score   (accuracy)\n",
      "\t0.09s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 2 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.2781\t = Validation score   (accuracy)\n",
      "\t6.53s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ...\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1616\t = Validation score   (accuracy)\n",
      "\t0.85s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.2781\t = Validation score   (accuracy)\n",
      "\t0.1s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 34.85s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220406_182830\\\")\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(label=label, eval_metric=metric).fit(train_data,\n",
    "    num_bag_folds=5, num_bag_sets=1, num_stack_levels=1,\n",
    "    hyperparameters = {'NN_TORCH': {'num_epochs': 2}, 'GBM': {'num_boost_round': 20}},  # last  argument is just for quick demo here, omit it in real applications\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UUmFSxYxrjNT"
   },
   "source": [
    "Nie powinniśmy dostarczać `tuning_data` gdy używamy `stacking'u / bagging'u`. Powinniśmy wszystkie dane przekazać w argumencie `train_data`, wtedy **AutoGluon** podzieli je w inteligenty sposób. \n",
    "\n",
    "`num_bag_stacks` określa ile razy k-fold'owy bagging ma zostać powtórzony. Zamiast ręcznie wyszukiwać optymalne parametry, AutoGluon automatycznie wybierze odpowiednie wartości gdy określimy parametr `auto_stack = True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "NVwi-Md7rjNT",
    "outputId": "b4cda0f6-dc56-472c-bea4-c504a2f09af4",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"agModels-predictOccupation\"\n",
      "Beginning AutoGluon training ... Time limit = 30s\n",
      "AutoGluon will save models to \"agModels-predictOccupation\\\"\n",
      "AutoGluon Version:  0.4.0\n",
      "Python Version:     3.9.7\n",
      "Operating System:   Windows\n",
      "Train Data Rows:    500\n",
      "Train Data Columns: 14\n",
      "Label Column: occupation\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\tFirst 10 (of 15) unique label values:  [' Exec-managerial', ' Other-service', ' Craft-repair', ' Sales', ' Prof-specialty', ' Protective-serv', ' ?', ' Adm-clerical', ' Machine-op-inspct', ' Tech-support']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 12 out of 15 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.978\n",
      "Train Data Class Count: 12\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    6778.49 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.28 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'relationship', 'race', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 6 | ['workclass', 'education', 'marital-status', 'relationship', 'race', ...]\n",
      "\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('int', ['bool']) : 2 | ['sex', 'class']\n",
      "\t0.1s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.13s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Fitting 2 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 29.87s of the 29.87s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.3067\t = Validation score   (accuracy)\n",
      "\t1.02s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 22.09s of the 22.09s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "2022-04-06 20:29:17,660\tWARNING worker.py:1227 -- The actor or task with ID 93d36530bd17a268a5b3d78c0954dfb4420d348890fc2dfc cannot be scheduled right now. You can ignore this message if this Ray cluster is expected to auto-scale or if you specified a runtime_env for this actor or task, which may take time to install.  Otherwise, this is likely due to all cluster resources being claimed by actors. To resolve the issue, consider creating fewer actors or increasing the resources available to this Ray cluster.\n",
      "Required resources for this actor or task: {CPU: 2.000000}\n",
      "Available resources on this node: {2.000000/12.000000 CPU, 229593120.068359 GiB/229593120.068359 GiB memory, 1.000000/1.000000 GPU, 114796559.960938 GiB/114796559.960938 GiB object_store_memory, 1.000000/1.000000 node:192.168.0.95}\n",
      "In total there are 5 pending tasks and 0 pending actors on this node.\n",
      "\t0.1656\t = Validation score   (accuracy)\n",
      "\t0.87s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 29.87s of the 14.59s of remaining time.\n",
      "\t0.3067\t = Validation score   (accuracy)\n",
      "\t0.09s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 15.52s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-predictOccupation\\\")\n"
     ]
    }
   ],
   "source": [
    "save_path = 'agModels-predictOccupation' \n",
    "\n",
    "predictor = TabularPredictor(label=label, eval_metric=metric, path=save_path).fit(\n",
    "    train_data, auto_stack=True,\n",
    "    time_limit=30, hyperparameters={'NN_TORCH': {'num_epochs': 2}, 'GBM': {'num_boost_round': 20}}  # małe wartości - demo\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sOEg6nnlrjNT"
   },
   "source": [
    "Najczęściej stacking/bagging daje lepsze rezultaty aniżeli optymalizacja hiperparametrów, lecz najlepiej połączyć obydwie opcje poprzez np. `presets = best_quality` i `auto_stack = True`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xDmMUNTerjNT"
   },
   "source": [
    "## Wczytywanie modelu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Zy4S1sHorjNT"
   },
   "outputs": [],
   "source": [
    "predictor = TabularPredictor.load(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "4B9a7TIRrjNT",
    "outputId": "74a28ec7-1b0c-4997-b5cd-c6281edcf824",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'workclass',\n",
       " 'fnlwgt',\n",
       " 'education',\n",
       " 'education-num',\n",
       " 'marital-status',\n",
       " 'relationship',\n",
       " 'race',\n",
       " 'sex',\n",
       " 'capital-gain',\n",
       " 'capital-loss',\n",
       " 'hours-per-week',\n",
       " 'native-country',\n",
       " 'class']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Ktw9MbV1rjNU",
    "outputId": "320910a8-9b42-436f-9b0a-8c37a7f3de89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      age workclass  fnlwgt      education  education-num marital-status  \\\n",
      "5000   49   Private  259087   Some-college             10       Divorced   \n",
      "\n",
      "        relationship    race      sex  capital-gain  capital-loss  \\\n",
      "5000   Not-in-family   White   Female             0             0   \n",
      "\n",
      "      hours-per-week  native-country   class  \n",
      "5000              40   United-States   <=50K  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5000     Exec-managerial\n",
       "Name: occupation, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapoint = test_data_nolabel.iloc[[0]] \n",
    "print(datapoint)\n",
    "predictor.predict(datapoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "cH3djlGzrjNU",
    "outputId": "68e63392-160c-4ee8-a38b-bce31a0423e5",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>?</th>\n",
       "      <th>Adm-clerical</th>\n",
       "      <th>Armed-Forces</th>\n",
       "      <th>Craft-repair</th>\n",
       "      <th>Exec-managerial</th>\n",
       "      <th>Farming-fishing</th>\n",
       "      <th>Handlers-cleaners</th>\n",
       "      <th>Machine-op-inspct</th>\n",
       "      <th>Other-service</th>\n",
       "      <th>Priv-house-serv</th>\n",
       "      <th>Prof-specialty</th>\n",
       "      <th>Protective-serv</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Tech-support</th>\n",
       "      <th>Transport-moving</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>0.039175</td>\n",
       "      <td>0.162921</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137995</td>\n",
       "      <td>0.224462</td>\n",
       "      <td>0.016408</td>\n",
       "      <td>0.03551</td>\n",
       "      <td>0.053049</td>\n",
       "      <td>0.062912</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.088034</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.110987</td>\n",
       "      <td>0.018565</td>\n",
       "      <td>0.049983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ?   Adm-clerical   Armed-Forces   Craft-repair   Exec-managerial  \\\n",
       "5000  0.039175       0.162921            0.0       0.137995          0.224462   \n",
       "\n",
       "       Farming-fishing   Handlers-cleaners   Machine-op-inspct  \\\n",
       "5000          0.016408             0.03551            0.053049   \n",
       "\n",
       "       Other-service   Priv-house-serv   Prof-specialty   Protective-serv  \\\n",
       "5000        0.062912               0.0         0.088034               0.0   \n",
       "\n",
       "         Sales   Tech-support   Transport-moving  \n",
       "5000  0.110987       0.018565           0.049983  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.predict_proba(datapoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "kP7U4kIFrjNU",
    "outputId": "d067fd44-c523-48fd-a25b-9bc0dbe018d5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WeightedEnsemble_L2'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.get_model_best()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "TBiT6I7BrjNU",
    "outputId": "b8823c02-2cef-4a74-d52f-5320213cdd3f",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM_BAG_L1</td>\n",
       "      <td>0.281610</td>\n",
       "      <td>0.306748</td>\n",
       "      <td>0.093580</td>\n",
       "      <td>0.031026</td>\n",
       "      <td>1.019876</td>\n",
       "      <td>0.093580</td>\n",
       "      <td>0.031026</td>\n",
       "      <td>1.019876</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.281610</td>\n",
       "      <td>0.306748</td>\n",
       "      <td>0.096082</td>\n",
       "      <td>0.031026</td>\n",
       "      <td>1.108452</td>\n",
       "      <td>0.002501</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088576</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NeuralNetTorch_BAG_L1</td>\n",
       "      <td>0.177605</td>\n",
       "      <td>0.165644</td>\n",
       "      <td>0.533958</td>\n",
       "      <td>0.058551</td>\n",
       "      <td>0.870246</td>\n",
       "      <td>0.533958</td>\n",
       "      <td>0.058551</td>\n",
       "      <td>0.870246</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   model  score_test  score_val  pred_time_test  \\\n",
       "0        LightGBM_BAG_L1    0.281610   0.306748        0.093580   \n",
       "1    WeightedEnsemble_L2    0.281610   0.306748        0.096082   \n",
       "2  NeuralNetTorch_BAG_L1    0.177605   0.165644        0.533958   \n",
       "\n",
       "   pred_time_val  fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0       0.031026  1.019876                 0.093580                0.031026   \n",
       "1       0.031026  1.108452                 0.002501                0.000000   \n",
       "2       0.058551  0.870246                 0.533958                0.058551   \n",
       "\n",
       "   fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0           1.019876            1       True          1  \n",
       "1           0.088576            2       True          3  \n",
       "2           0.870246            1       True          2  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(test_data, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "YtCsBsWKrjNU",
    "outputId": "78785d49-a35e-42fd-bee5-e81847300db6",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM_BAG_L1</td>\n",
       "      <td>0.281610</td>\n",
       "      <td>0.281610</td>\n",
       "      <td>0.306748</td>\n",
       "      <td>0.072561</td>\n",
       "      <td>0.031026</td>\n",
       "      <td>1.019876</td>\n",
       "      <td>0.072561</td>\n",
       "      <td>0.031026</td>\n",
       "      <td>1.019876</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.281610</td>\n",
       "      <td>0.281610</td>\n",
       "      <td>0.306748</td>\n",
       "      <td>0.074563</td>\n",
       "      <td>0.031026</td>\n",
       "      <td>1.108452</td>\n",
       "      <td>0.002002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088576</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NeuralNetTorch_BAG_L1</td>\n",
       "      <td>0.177605</td>\n",
       "      <td>0.177605</td>\n",
       "      <td>0.165644</td>\n",
       "      <td>0.455391</td>\n",
       "      <td>0.058551</td>\n",
       "      <td>0.870246</td>\n",
       "      <td>0.455391</td>\n",
       "      <td>0.058551</td>\n",
       "      <td>0.870246</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   model  score_test  accuracy  score_val  pred_time_test  \\\n",
       "0        LightGBM_BAG_L1    0.281610  0.281610   0.306748        0.072561   \n",
       "1    WeightedEnsemble_L2    0.281610  0.281610   0.306748        0.074563   \n",
       "2  NeuralNetTorch_BAG_L1    0.177605  0.177605   0.165644        0.455391   \n",
       "\n",
       "   pred_time_val  fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0       0.031026  1.019876                 0.072561                0.031026   \n",
       "1       0.031026  1.108452                 0.002002                0.000000   \n",
       "2       0.058551  0.870246                 0.455391                0.058551   \n",
       "\n",
       "   fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0           1.019876            1       True          1  \n",
       "1           0.088576            2       True          3  \n",
       "2           0.870246            1       True          2  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(test_data, extra_metrics=['accuracy'], silent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5eD5Eq2LrjNU"
   },
   "source": [
    "Możemy wybrać który model chcemy żeby robił predykcje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "3zZI9IhqrjNV",
    "outputId": "84178421-76ce-459f-c165-5eb67a025a40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction from LightGBM_BAG_L1 model:  Exec-managerial\n"
     ]
    }
   ],
   "source": [
    "i = 0 \n",
    "model_to_use = predictor.get_model_names()[i]\n",
    "model_pred = predictor.predict(datapoint, model=model_to_use)\n",
    "print(\"Prediction from %s model: %s\" % (model_to_use, model_pred.iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "mmy6dVz8rjNV"
   },
   "outputs": [],
   "source": [
    "all_models = predictor.get_model_names()\n",
    "model_to_use = all_models[i]\n",
    "specific_model = predictor._trainer.load_model(model_to_use)\n",
    "\n",
    "\n",
    "model_info = specific_model.get_info()\n",
    "predictor_information = predictor.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "AzY_Dp24rjNV",
    "outputId": "be1329c3-7170-4aef-b02f-79bcb94adcc1",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'LightGBM_BAG_L1',\n",
       " 'model_type': 'StackerEnsembleModel',\n",
       " 'problem_type': 'multiclass',\n",
       " 'eval_metric': 'accuracy',\n",
       " 'stopping_metric': 'accuracy',\n",
       " 'fit_time': 1.0198757648468018,\n",
       " 'num_classes': 12,\n",
       " 'quantile_levels': None,\n",
       " 'predict_time': 0.031026124954223633,\n",
       " 'val_score': 0.3067484662576687,\n",
       " 'hyperparameters': {'use_orig_features': True,\n",
       "  'max_base_models': 25,\n",
       "  'max_base_models_per_type': 5,\n",
       "  'save_bag_folds': True},\n",
       " 'hyperparameters_fit': {},\n",
       " 'hyperparameters_nondefault': [],\n",
       " 'ag_args_fit': {'max_memory_usage_ratio': 1.0,\n",
       "  'max_time_limit_ratio': 1.0,\n",
       "  'max_time_limit': None,\n",
       "  'min_time_limit': 0,\n",
       "  'valid_raw_types': None,\n",
       "  'valid_special_types': None,\n",
       "  'ignored_type_group_special': None,\n",
       "  'ignored_type_group_raw': None,\n",
       "  'get_features_kwargs': None,\n",
       "  'get_features_kwargs_extra': None,\n",
       "  'predict_1_batch_size': None,\n",
       "  'drop_unique': False},\n",
       " 'num_features': 14,\n",
       " 'features': ['age',\n",
       "  'sex',\n",
       "  'capital-loss',\n",
       "  'education',\n",
       "  'fnlwgt',\n",
       "  'education-num',\n",
       "  'marital-status',\n",
       "  'race',\n",
       "  'workclass',\n",
       "  'hours-per-week',\n",
       "  'native-country',\n",
       "  'capital-gain',\n",
       "  'class',\n",
       "  'relationship'],\n",
       " 'feature_metadata': <autogluon.common.features.feature_metadata.FeatureMetadata at 0x27d2f428460>,\n",
       " 'memory_size': 2865,\n",
       " 'bagged_info': {'child_model_type': 'LGBModel',\n",
       "  'num_child_models': 5,\n",
       "  'child_model_names': ['S1F5', 'S1F3', 'S1F2', 'S1F4', 'S1F1'],\n",
       "  '_n_repeats': 1,\n",
       "  '_k_per_n_repeat': [5],\n",
       "  '_random_state': 1,\n",
       "  'low_memory': True,\n",
       "  'bagged_mode': True,\n",
       "  'max_memory_size': 973026,\n",
       "  'min_memory_size': 342349,\n",
       "  'child_hyperparameters': {'learning_rate': 0.05, 'num_boost_round': 20},\n",
       "  'child_hyperparameters_fit': {'num_boost_round': 9},\n",
       "  'child_ag_args_fit': {'max_memory_usage_ratio': 1.0,\n",
       "   'max_time_limit_ratio': 1.0,\n",
       "   'max_time_limit': None,\n",
       "   'min_time_limit': 0,\n",
       "   'valid_raw_types': ['bool', 'int', 'float', 'category'],\n",
       "   'valid_special_types': None,\n",
       "   'ignored_type_group_special': None,\n",
       "   'ignored_type_group_raw': None,\n",
       "   'get_features_kwargs': None,\n",
       "   'get_features_kwargs_extra': None,\n",
       "   'predict_1_batch_size': None}},\n",
       " 'stacker_info': {'num_base_models': 0, 'base_model_names': []},\n",
       " 'children_info': {'S1F5': {'name': 'S1F5',\n",
       "   'model_type': 'LGBModel',\n",
       "   'problem_type': 'multiclass',\n",
       "   'eval_metric': 'accuracy',\n",
       "   'stopping_metric': 'accuracy',\n",
       "   'fit_time': 0.9623262882232666,\n",
       "   'num_classes': 12,\n",
       "   'quantile_levels': None,\n",
       "   'predict_time': 0.0055043697357177734,\n",
       "   'val_score': 0.31958762886597936,\n",
       "   'hyperparameters': {'learning_rate': 0.05, 'num_boost_round': 20},\n",
       "   'hyperparameters_fit': {'num_boost_round': 5},\n",
       "   'hyperparameters_nondefault': ['num_boost_round'],\n",
       "   'ag_args_fit': {'max_memory_usage_ratio': 1.0,\n",
       "    'max_time_limit_ratio': 1.0,\n",
       "    'max_time_limit': None,\n",
       "    'min_time_limit': 0,\n",
       "    'valid_raw_types': ['bool', 'int', 'float', 'category'],\n",
       "    'valid_special_types': None,\n",
       "    'ignored_type_group_special': None,\n",
       "    'ignored_type_group_raw': None,\n",
       "    'get_features_kwargs': None,\n",
       "    'get_features_kwargs_extra': None,\n",
       "    'predict_1_batch_size': None},\n",
       "   'num_features': 14,\n",
       "   'features': ['age',\n",
       "    'fnlwgt',\n",
       "    'education-num',\n",
       "    'sex',\n",
       "    'capital-gain',\n",
       "    'capital-loss',\n",
       "    'hours-per-week',\n",
       "    'class',\n",
       "    'workclass',\n",
       "    'education',\n",
       "    'marital-status',\n",
       "    'relationship',\n",
       "    'race',\n",
       "    'native-country'],\n",
       "   'feature_metadata': <autogluon.common.features.feature_metadata.FeatureMetadata at 0x27d36cf6d00>,\n",
       "   'memory_size': 104548},\n",
       "  'S1F3': {'name': 'S1F3',\n",
       "   'model_type': 'LGBModel',\n",
       "   'problem_type': 'multiclass',\n",
       "   'eval_metric': 'accuracy',\n",
       "   'stopping_metric': 'accuracy',\n",
       "   'fit_time': 0.9713327884674072,\n",
       "   'num_classes': 12,\n",
       "   'quantile_levels': None,\n",
       "   'predict_time': 0.006005287170410156,\n",
       "   'val_score': 0.2653061224489796,\n",
       "   'hyperparameters': {'learning_rate': 0.05, 'num_boost_round': 20},\n",
       "   'hyperparameters_fit': {'num_boost_round': 6},\n",
       "   'hyperparameters_nondefault': ['num_boost_round'],\n",
       "   'ag_args_fit': {'max_memory_usage_ratio': 1.0,\n",
       "    'max_time_limit_ratio': 1.0,\n",
       "    'max_time_limit': None,\n",
       "    'min_time_limit': 0,\n",
       "    'valid_raw_types': ['bool', 'int', 'float', 'category'],\n",
       "    'valid_special_types': None,\n",
       "    'ignored_type_group_special': None,\n",
       "    'ignored_type_group_raw': None,\n",
       "    'get_features_kwargs': None,\n",
       "    'get_features_kwargs_extra': None,\n",
       "    'predict_1_batch_size': None},\n",
       "   'num_features': 14,\n",
       "   'features': ['age',\n",
       "    'fnlwgt',\n",
       "    'education-num',\n",
       "    'sex',\n",
       "    'capital-gain',\n",
       "    'capital-loss',\n",
       "    'hours-per-week',\n",
       "    'class',\n",
       "    'workclass',\n",
       "    'education',\n",
       "    'marital-status',\n",
       "    'relationship',\n",
       "    'race',\n",
       "    'native-country'],\n",
       "   'feature_metadata': <autogluon.common.features.feature_metadata.FeatureMetadata at 0x27d2f323fa0>,\n",
       "   'memory_size': 126656},\n",
       "  'S1F2': {'name': 'S1F2',\n",
       "   'model_type': 'LGBModel',\n",
       "   'problem_type': 'multiclass',\n",
       "   'eval_metric': 'accuracy',\n",
       "   'stopping_metric': 'accuracy',\n",
       "   'fit_time': 0.9828438758850098,\n",
       "   'num_classes': 12,\n",
       "   'quantile_levels': None,\n",
       "   'predict_time': 0.0065059661865234375,\n",
       "   'val_score': 0.336734693877551,\n",
       "   'hyperparameters': {'learning_rate': 0.05, 'num_boost_round': 20},\n",
       "   'hyperparameters_fit': {'num_boost_round': 14},\n",
       "   'hyperparameters_nondefault': ['num_boost_round'],\n",
       "   'ag_args_fit': {'max_memory_usage_ratio': 1.0,\n",
       "    'max_time_limit_ratio': 1.0,\n",
       "    'max_time_limit': None,\n",
       "    'min_time_limit': 0,\n",
       "    'valid_raw_types': ['bool', 'int', 'float', 'category'],\n",
       "    'valid_special_types': None,\n",
       "    'ignored_type_group_special': None,\n",
       "    'ignored_type_group_raw': None,\n",
       "    'get_features_kwargs': None,\n",
       "    'get_features_kwargs_extra': None,\n",
       "    'predict_1_batch_size': None},\n",
       "   'num_features': 14,\n",
       "   'features': ['age',\n",
       "    'fnlwgt',\n",
       "    'education-num',\n",
       "    'sex',\n",
       "    'capital-gain',\n",
       "    'capital-loss',\n",
       "    'hours-per-week',\n",
       "    'class',\n",
       "    'workclass',\n",
       "    'education',\n",
       "    'marital-status',\n",
       "    'relationship',\n",
       "    'race',\n",
       "    'native-country'],\n",
       "   'feature_metadata': <autogluon.common.features.feature_metadata.FeatureMetadata at 0x27d36d99130>,\n",
       "   'memory_size': 294001},\n",
       "  'S1F4': {'name': 'S1F4',\n",
       "   'model_type': 'LGBModel',\n",
       "   'problem_type': 'multiclass',\n",
       "   'eval_metric': 'accuracy',\n",
       "   'stopping_metric': 'accuracy',\n",
       "   'fit_time': 0.9758384227752686,\n",
       "   'num_classes': 12,\n",
       "   'quantile_levels': None,\n",
       "   'predict_time': 0.006505250930786133,\n",
       "   'val_score': 0.3163265306122449,\n",
       "   'hyperparameters': {'learning_rate': 0.05, 'num_boost_round': 20},\n",
       "   'hyperparameters_fit': {'num_boost_round': 16},\n",
       "   'hyperparameters_nondefault': ['num_boost_round'],\n",
       "   'ag_args_fit': {'max_memory_usage_ratio': 1.0,\n",
       "    'max_time_limit_ratio': 1.0,\n",
       "    'max_time_limit': None,\n",
       "    'min_time_limit': 0,\n",
       "    'valid_raw_types': ['bool', 'int', 'float', 'category'],\n",
       "    'valid_special_types': None,\n",
       "    'ignored_type_group_special': None,\n",
       "    'ignored_type_group_raw': None,\n",
       "    'get_features_kwargs': None,\n",
       "    'get_features_kwargs_extra': None,\n",
       "    'predict_1_batch_size': None},\n",
       "   'num_features': 14,\n",
       "   'features': ['age',\n",
       "    'fnlwgt',\n",
       "    'education-num',\n",
       "    'sex',\n",
       "    'capital-gain',\n",
       "    'capital-loss',\n",
       "    'hours-per-week',\n",
       "    'class',\n",
       "    'workclass',\n",
       "    'education',\n",
       "    'marital-status',\n",
       "    'relationship',\n",
       "    'race',\n",
       "    'native-country'],\n",
       "   'feature_metadata': <autogluon.common.features.feature_metadata.FeatureMetadata at 0x27d3863cee0>,\n",
       "   'memory_size': 339484},\n",
       "  'S1F1': {'name': 'S1F1',\n",
       "   'model_type': 'LGBModel',\n",
       "   'problem_type': 'multiclass',\n",
       "   'eval_metric': 'accuracy',\n",
       "   'stopping_metric': 'accuracy',\n",
       "   'fit_time': 0.9668307304382324,\n",
       "   'num_classes': 12,\n",
       "   'quantile_levels': None,\n",
       "   'predict_time': 0.006505250930786133,\n",
       "   'val_score': 0.29591836734693877,\n",
       "   'hyperparameters': {'learning_rate': 0.05, 'num_boost_round': 20},\n",
       "   'hyperparameters_fit': {'num_boost_round': 5},\n",
       "   'hyperparameters_nondefault': ['num_boost_round'],\n",
       "   'ag_args_fit': {'max_memory_usage_ratio': 1.0,\n",
       "    'max_time_limit_ratio': 1.0,\n",
       "    'max_time_limit': None,\n",
       "    'min_time_limit': 0,\n",
       "    'valid_raw_types': ['bool', 'int', 'float', 'category'],\n",
       "    'valid_special_types': None,\n",
       "    'ignored_type_group_special': None,\n",
       "    'ignored_type_group_raw': None,\n",
       "    'get_features_kwargs': None,\n",
       "    'get_features_kwargs_extra': None,\n",
       "    'predict_1_batch_size': None},\n",
       "   'num_features': 14,\n",
       "   'features': ['age',\n",
       "    'fnlwgt',\n",
       "    'education-num',\n",
       "    'sex',\n",
       "    'capital-gain',\n",
       "    'capital-loss',\n",
       "    'hours-per-week',\n",
       "    'class',\n",
       "    'workclass',\n",
       "    'education',\n",
       "    'marital-status',\n",
       "    'relationship',\n",
       "    'race',\n",
       "    'native-country'],\n",
       "   'feature_metadata': <autogluon.common.features.feature_metadata.FeatureMetadata at 0x27d3829ca00>,\n",
       "   'memory_size': 105472}}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "tA8gBDTGrjNV",
    "outputId": "9060245d-63a9-4369-b654-394d2c0b05e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': 'agModels-predictOccupation\\\\',\n",
       " 'label': 'occupation',\n",
       " 'random_state': 0,\n",
       " 'version': '0.4.0',\n",
       " 'features': ['age',\n",
       "  'workclass',\n",
       "  'fnlwgt',\n",
       "  'education',\n",
       "  'education-num',\n",
       "  'marital-status',\n",
       "  'relationship',\n",
       "  'race',\n",
       "  'sex',\n",
       "  'capital-gain',\n",
       "  'capital-loss',\n",
       "  'hours-per-week',\n",
       "  'native-country',\n",
       "  'class'],\n",
       " 'feature_metadata_in': <autogluon.common.features.feature_metadata.FeatureMetadata at 0x27d36d18430>,\n",
       " 'time_fit_preprocessing': 0.13311433792114258,\n",
       " 'time_fit_training': 15.387544393539429,\n",
       " 'time_fit_total': 15.520658731460571,\n",
       " 'time_limit': 30,\n",
       " 'time_train_start': 1649269745.6012566,\n",
       " 'num_rows_train': 489,\n",
       " 'num_cols_train': 14,\n",
       " 'num_classes': 12,\n",
       " 'problem_type': 'multiclass',\n",
       " 'eval_metric': 'accuracy',\n",
       " 'best_model': 'WeightedEnsemble_L2',\n",
       " 'best_model_score_val': 0.3067484662576687,\n",
       " 'best_model_stack_level': 2,\n",
       " 'num_models_trained': 3,\n",
       " 'num_bag_folds': 5,\n",
       " 'max_stack_level': 2,\n",
       " 'max_core_stack_level': 1,\n",
       " 'model_info': {'LightGBM_BAG_L1': {'name': 'LightGBM_BAG_L1',\n",
       "   'model_type': 'StackerEnsembleModel',\n",
       "   'problem_type': 'multiclass',\n",
       "   'eval_metric': 'accuracy',\n",
       "   'stopping_metric': 'accuracy',\n",
       "   'fit_time': 1.0198757648468018,\n",
       "   'num_classes': 12,\n",
       "   'quantile_levels': None,\n",
       "   'predict_time': 0.031026124954223633,\n",
       "   'val_score': 0.3067484662576687,\n",
       "   'hyperparameters': {'use_orig_features': True,\n",
       "    'max_base_models': 25,\n",
       "    'max_base_models_per_type': 5,\n",
       "    'save_bag_folds': True},\n",
       "   'hyperparameters_fit': {},\n",
       "   'hyperparameters_nondefault': [],\n",
       "   'ag_args_fit': {'max_memory_usage_ratio': 1.0,\n",
       "    'max_time_limit_ratio': 1.0,\n",
       "    'max_time_limit': None,\n",
       "    'min_time_limit': 0,\n",
       "    'valid_raw_types': None,\n",
       "    'valid_special_types': None,\n",
       "    'ignored_type_group_special': None,\n",
       "    'ignored_type_group_raw': None,\n",
       "    'get_features_kwargs': None,\n",
       "    'get_features_kwargs_extra': None,\n",
       "    'predict_1_batch_size': None,\n",
       "    'drop_unique': False},\n",
       "   'num_features': 14,\n",
       "   'features': ['age',\n",
       "    'sex',\n",
       "    'capital-loss',\n",
       "    'education',\n",
       "    'fnlwgt',\n",
       "    'education-num',\n",
       "    'marital-status',\n",
       "    'race',\n",
       "    'workclass',\n",
       "    'hours-per-week',\n",
       "    'native-country',\n",
       "    'capital-gain',\n",
       "    'class',\n",
       "    'relationship'],\n",
       "   'feature_metadata': <autogluon.common.features.feature_metadata.FeatureMetadata at 0x27d36d66e50>,\n",
       "   'memory_size': 2865,\n",
       "   'bagged_info': {'child_model_type': 'LGBModel',\n",
       "    'num_child_models': 5,\n",
       "    'child_model_names': ['S1F5', 'S1F3', 'S1F2', 'S1F4', 'S1F1'],\n",
       "    '_n_repeats': 1,\n",
       "    '_k_per_n_repeat': [5],\n",
       "    '_random_state': 1,\n",
       "    'low_memory': True,\n",
       "    'bagged_mode': True,\n",
       "    'max_memory_size': 973026,\n",
       "    'min_memory_size': 342349,\n",
       "    'child_hyperparameters': {'learning_rate': 0.05, 'num_boost_round': 20},\n",
       "    'child_hyperparameters_fit': {'num_boost_round': 9},\n",
       "    'child_ag_args_fit': {'max_memory_usage_ratio': 1.0,\n",
       "     'max_time_limit_ratio': 1.0,\n",
       "     'max_time_limit': None,\n",
       "     'min_time_limit': 0,\n",
       "     'valid_raw_types': ['bool', 'int', 'float', 'category'],\n",
       "     'valid_special_types': None,\n",
       "     'ignored_type_group_special': None,\n",
       "     'ignored_type_group_raw': None,\n",
       "     'get_features_kwargs': None,\n",
       "     'get_features_kwargs_extra': None,\n",
       "     'predict_1_batch_size': None}},\n",
       "   'stacker_info': {'num_base_models': 0, 'base_model_names': []},\n",
       "   'children_info': {'S1F5': {'name': 'S1F5',\n",
       "     'model_type': 'LGBModel',\n",
       "     'problem_type': 'multiclass',\n",
       "     'eval_metric': 'accuracy',\n",
       "     'stopping_metric': 'accuracy',\n",
       "     'fit_time': 0.9623262882232666,\n",
       "     'num_classes': 12,\n",
       "     'quantile_levels': None,\n",
       "     'predict_time': 0.0055043697357177734,\n",
       "     'val_score': 0.31958762886597936,\n",
       "     'hyperparameters': {'learning_rate': 0.05, 'num_boost_round': 20},\n",
       "     'hyperparameters_fit': {'num_boost_round': 5},\n",
       "     'hyperparameters_nondefault': ['num_boost_round'],\n",
       "     'ag_args_fit': {'max_memory_usage_ratio': 1.0,\n",
       "      'max_time_limit_ratio': 1.0,\n",
       "      'max_time_limit': None,\n",
       "      'min_time_limit': 0,\n",
       "      'valid_raw_types': ['bool', 'int', 'float', 'category'],\n",
       "      'valid_special_types': None,\n",
       "      'ignored_type_group_special': None,\n",
       "      'ignored_type_group_raw': None,\n",
       "      'get_features_kwargs': None,\n",
       "      'get_features_kwargs_extra': None,\n",
       "      'predict_1_batch_size': None},\n",
       "     'num_features': 14,\n",
       "     'features': ['age',\n",
       "      'fnlwgt',\n",
       "      'education-num',\n",
       "      'sex',\n",
       "      'capital-gain',\n",
       "      'capital-loss',\n",
       "      'hours-per-week',\n",
       "      'class',\n",
       "      'workclass',\n",
       "      'education',\n",
       "      'marital-status',\n",
       "      'relationship',\n",
       "      'race',\n",
       "      'native-country'],\n",
       "     'feature_metadata': <autogluon.common.features.feature_metadata.FeatureMetadata at 0x27d36d665b0>,\n",
       "     'memory_size': 104548},\n",
       "    'S1F3': {'name': 'S1F3',\n",
       "     'model_type': 'LGBModel',\n",
       "     'problem_type': 'multiclass',\n",
       "     'eval_metric': 'accuracy',\n",
       "     'stopping_metric': 'accuracy',\n",
       "     'fit_time': 0.9713327884674072,\n",
       "     'num_classes': 12,\n",
       "     'quantile_levels': None,\n",
       "     'predict_time': 0.006005287170410156,\n",
       "     'val_score': 0.2653061224489796,\n",
       "     'hyperparameters': {'learning_rate': 0.05, 'num_boost_round': 20},\n",
       "     'hyperparameters_fit': {'num_boost_round': 6},\n",
       "     'hyperparameters_nondefault': ['num_boost_round'],\n",
       "     'ag_args_fit': {'max_memory_usage_ratio': 1.0,\n",
       "      'max_time_limit_ratio': 1.0,\n",
       "      'max_time_limit': None,\n",
       "      'min_time_limit': 0,\n",
       "      'valid_raw_types': ['bool', 'int', 'float', 'category'],\n",
       "      'valid_special_types': None,\n",
       "      'ignored_type_group_special': None,\n",
       "      'ignored_type_group_raw': None,\n",
       "      'get_features_kwargs': None,\n",
       "      'get_features_kwargs_extra': None,\n",
       "      'predict_1_batch_size': None},\n",
       "     'num_features': 14,\n",
       "     'features': ['age',\n",
       "      'fnlwgt',\n",
       "      'education-num',\n",
       "      'sex',\n",
       "      'capital-gain',\n",
       "      'capital-loss',\n",
       "      'hours-per-week',\n",
       "      'class',\n",
       "      'workclass',\n",
       "      'education',\n",
       "      'marital-status',\n",
       "      'relationship',\n",
       "      'race',\n",
       "      'native-country'],\n",
       "     'feature_metadata': <autogluon.common.features.feature_metadata.FeatureMetadata at 0x27d36d998e0>,\n",
       "     'memory_size': 126656},\n",
       "    'S1F2': {'name': 'S1F2',\n",
       "     'model_type': 'LGBModel',\n",
       "     'problem_type': 'multiclass',\n",
       "     'eval_metric': 'accuracy',\n",
       "     'stopping_metric': 'accuracy',\n",
       "     'fit_time': 0.9828438758850098,\n",
       "     'num_classes': 12,\n",
       "     'quantile_levels': None,\n",
       "     'predict_time': 0.0065059661865234375,\n",
       "     'val_score': 0.336734693877551,\n",
       "     'hyperparameters': {'learning_rate': 0.05, 'num_boost_round': 20},\n",
       "     'hyperparameters_fit': {'num_boost_round': 14},\n",
       "     'hyperparameters_nondefault': ['num_boost_round'],\n",
       "     'ag_args_fit': {'max_memory_usage_ratio': 1.0,\n",
       "      'max_time_limit_ratio': 1.0,\n",
       "      'max_time_limit': None,\n",
       "      'min_time_limit': 0,\n",
       "      'valid_raw_types': ['bool', 'int', 'float', 'category'],\n",
       "      'valid_special_types': None,\n",
       "      'ignored_type_group_special': None,\n",
       "      'ignored_type_group_raw': None,\n",
       "      'get_features_kwargs': None,\n",
       "      'get_features_kwargs_extra': None,\n",
       "      'predict_1_batch_size': None},\n",
       "     'num_features': 14,\n",
       "     'features': ['age',\n",
       "      'fnlwgt',\n",
       "      'education-num',\n",
       "      'sex',\n",
       "      'capital-gain',\n",
       "      'capital-loss',\n",
       "      'hours-per-week',\n",
       "      'class',\n",
       "      'workclass',\n",
       "      'education',\n",
       "      'marital-status',\n",
       "      'relationship',\n",
       "      'race',\n",
       "      'native-country'],\n",
       "     'feature_metadata': <autogluon.common.features.feature_metadata.FeatureMetadata at 0x27d2f428730>,\n",
       "     'memory_size': 294001},\n",
       "    'S1F4': {'name': 'S1F4',\n",
       "     'model_type': 'LGBModel',\n",
       "     'problem_type': 'multiclass',\n",
       "     'eval_metric': 'accuracy',\n",
       "     'stopping_metric': 'accuracy',\n",
       "     'fit_time': 0.9758384227752686,\n",
       "     'num_classes': 12,\n",
       "     'quantile_levels': None,\n",
       "     'predict_time': 0.006505250930786133,\n",
       "     'val_score': 0.3163265306122449,\n",
       "     'hyperparameters': {'learning_rate': 0.05, 'num_boost_round': 20},\n",
       "     'hyperparameters_fit': {'num_boost_round': 16},\n",
       "     'hyperparameters_nondefault': ['num_boost_round'],\n",
       "     'ag_args_fit': {'max_memory_usage_ratio': 1.0,\n",
       "      'max_time_limit_ratio': 1.0,\n",
       "      'max_time_limit': None,\n",
       "      'min_time_limit': 0,\n",
       "      'valid_raw_types': ['bool', 'int', 'float', 'category'],\n",
       "      'valid_special_types': None,\n",
       "      'ignored_type_group_special': None,\n",
       "      'ignored_type_group_raw': None,\n",
       "      'get_features_kwargs': None,\n",
       "      'get_features_kwargs_extra': None,\n",
       "      'predict_1_batch_size': None},\n",
       "     'num_features': 14,\n",
       "     'features': ['age',\n",
       "      'fnlwgt',\n",
       "      'education-num',\n",
       "      'sex',\n",
       "      'capital-gain',\n",
       "      'capital-loss',\n",
       "      'hours-per-week',\n",
       "      'class',\n",
       "      'workclass',\n",
       "      'education',\n",
       "      'marital-status',\n",
       "      'relationship',\n",
       "      'race',\n",
       "      'native-country'],\n",
       "     'feature_metadata': <autogluon.common.features.feature_metadata.FeatureMetadata at 0x27d2f421460>,\n",
       "     'memory_size': 339484},\n",
       "    'S1F1': {'name': 'S1F1',\n",
       "     'model_type': 'LGBModel',\n",
       "     'problem_type': 'multiclass',\n",
       "     'eval_metric': 'accuracy',\n",
       "     'stopping_metric': 'accuracy',\n",
       "     'fit_time': 0.9668307304382324,\n",
       "     'num_classes': 12,\n",
       "     'quantile_levels': None,\n",
       "     'predict_time': 0.006505250930786133,\n",
       "     'val_score': 0.29591836734693877,\n",
       "     'hyperparameters': {'learning_rate': 0.05, 'num_boost_round': 20},\n",
       "     'hyperparameters_fit': {'num_boost_round': 5},\n",
       "     'hyperparameters_nondefault': ['num_boost_round'],\n",
       "     'ag_args_fit': {'max_memory_usage_ratio': 1.0,\n",
       "      'max_time_limit_ratio': 1.0,\n",
       "      'max_time_limit': None,\n",
       "      'min_time_limit': 0,\n",
       "      'valid_raw_types': ['bool', 'int', 'float', 'category'],\n",
       "      'valid_special_types': None,\n",
       "      'ignored_type_group_special': None,\n",
       "      'ignored_type_group_raw': None,\n",
       "      'get_features_kwargs': None,\n",
       "      'get_features_kwargs_extra': None,\n",
       "      'predict_1_batch_size': None},\n",
       "     'num_features': 14,\n",
       "     'features': ['age',\n",
       "      'fnlwgt',\n",
       "      'education-num',\n",
       "      'sex',\n",
       "      'capital-gain',\n",
       "      'capital-loss',\n",
       "      'hours-per-week',\n",
       "      'class',\n",
       "      'workclass',\n",
       "      'education',\n",
       "      'marital-status',\n",
       "      'relationship',\n",
       "      'race',\n",
       "      'native-country'],\n",
       "     'feature_metadata': <autogluon.common.features.feature_metadata.FeatureMetadata at 0x27d2f4284c0>,\n",
       "     'memory_size': 105472}}},\n",
       "  'NeuralNetTorch_BAG_L1': {'name': 'NeuralNetTorch_BAG_L1',\n",
       "   'model_type': 'StackerEnsembleModel',\n",
       "   'problem_type': 'multiclass',\n",
       "   'eval_metric': 'accuracy',\n",
       "   'stopping_metric': 'accuracy',\n",
       "   'fit_time': 0.870246171951294,\n",
       "   'num_classes': 12,\n",
       "   'quantile_levels': None,\n",
       "   'predict_time': 0.05855131149291992,\n",
       "   'val_score': 0.1656441717791411,\n",
       "   'hyperparameters': {'use_orig_features': True,\n",
       "    'max_base_models': 25,\n",
       "    'max_base_models_per_type': 5,\n",
       "    'save_bag_folds': True},\n",
       "   'hyperparameters_fit': {},\n",
       "   'hyperparameters_nondefault': [],\n",
       "   'ag_args_fit': {'max_memory_usage_ratio': 1.0,\n",
       "    'max_time_limit_ratio': 1.0,\n",
       "    'max_time_limit': None,\n",
       "    'min_time_limit': 0,\n",
       "    'valid_raw_types': None,\n",
       "    'valid_special_types': None,\n",
       "    'ignored_type_group_special': None,\n",
       "    'ignored_type_group_raw': None,\n",
       "    'get_features_kwargs': None,\n",
       "    'get_features_kwargs_extra': None,\n",
       "    'predict_1_batch_size': None,\n",
       "    'drop_unique': False},\n",
       "   'num_features': 14,\n",
       "   'features': ['age',\n",
       "    'sex',\n",
       "    'capital-loss',\n",
       "    'education',\n",
       "    'fnlwgt',\n",
       "    'education-num',\n",
       "    'marital-status',\n",
       "    'race',\n",
       "    'workclass',\n",
       "    'hours-per-week',\n",
       "    'native-country',\n",
       "    'capital-gain',\n",
       "    'class',\n",
       "    'relationship'],\n",
       "   'feature_metadata': <autogluon.common.features.feature_metadata.FeatureMetadata at 0x27d36d66880>,\n",
       "   'memory_size': 2950,\n",
       "   'bagged_info': {'child_model_type': 'TabularNeuralNetTorchModel',\n",
       "    'num_child_models': 5,\n",
       "    'child_model_names': ['S1F4', 'S1F2', 'S1F3', 'S1F5', 'S1F1'],\n",
       "    '_n_repeats': 1,\n",
       "    '_k_per_n_repeat': [5],\n",
       "    '_random_state': 1,\n",
       "    'low_memory': True,\n",
       "    'bagged_mode': True,\n",
       "    'max_memory_size': 1276428,\n",
       "    'min_memory_size': 259136,\n",
       "    'child_hyperparameters': {'num_epochs': 2,\n",
       "     'epochs_wo_improve': 20,\n",
       "     'activation': 'relu',\n",
       "     'embedding_size_factor': 1.0,\n",
       "     'embed_exponent': 0.56,\n",
       "     'max_embedding_dim': 100,\n",
       "     'y_range': None,\n",
       "     'y_range_extend': 0.05,\n",
       "     'dropout_prob': 0.1,\n",
       "     'optimizer': 'adam',\n",
       "     'learning_rate': 0.0003,\n",
       "     'weight_decay': 1e-06,\n",
       "     'proc.embed_min_categories': 4,\n",
       "     'proc.impute_strategy': 'median',\n",
       "     'proc.max_category_levels': 100,\n",
       "     'proc.skew_threshold': 0.99,\n",
       "     'use_ngram_features': False,\n",
       "     'num_layers': 4,\n",
       "     'hidden_size': 128,\n",
       "     'max_batch_size': 512,\n",
       "     'use_batchnorm': False,\n",
       "     'loss_function': 'auto'},\n",
       "    'child_hyperparameters_fit': {'batch_size': 32, 'num_epochs': 2},\n",
       "    'child_ag_args_fit': {'max_memory_usage_ratio': 1.0,\n",
       "     'max_time_limit_ratio': 1.0,\n",
       "     'max_time_limit': None,\n",
       "     'min_time_limit': 0,\n",
       "     'valid_raw_types': ['bool', 'int', 'float', 'category'],\n",
       "     'valid_special_types': None,\n",
       "     'ignored_type_group_special': ['text_ngram', 'text_as_category'],\n",
       "     'ignored_type_group_raw': None,\n",
       "     'get_features_kwargs': None,\n",
       "     'get_features_kwargs_extra': None,\n",
       "     'predict_1_batch_size': None}},\n",
       "   'stacker_info': {'num_base_models': 0, 'base_model_names': []},\n",
       "   'children_info': {'S1F4': {'name': 'S1F4',\n",
       "     'model_type': 'TabularNeuralNetTorchModel',\n",
       "     'problem_type': 'multiclass',\n",
       "     'eval_metric': 'accuracy',\n",
       "     'stopping_metric': 'accuracy',\n",
       "     'fit_time': 0.8152008056640625,\n",
       "     'num_classes': 12,\n",
       "     'quantile_levels': None,\n",
       "     'predict_time': 0.012510538101196289,\n",
       "     'val_score': 0.15306122448979592,\n",
       "     'hyperparameters': {'num_epochs': 2,\n",
       "      'epochs_wo_improve': 20,\n",
       "      'activation': 'relu',\n",
       "      'embedding_size_factor': 1.0,\n",
       "      'embed_exponent': 0.56,\n",
       "      'max_embedding_dim': 100,\n",
       "      'y_range': None,\n",
       "      'y_range_extend': 0.05,\n",
       "      'dropout_prob': 0.1,\n",
       "      'optimizer': 'adam',\n",
       "      'learning_rate': 0.0003,\n",
       "      'weight_decay': 1e-06,\n",
       "      'proc.embed_min_categories': 4,\n",
       "      'proc.impute_strategy': 'median',\n",
       "      'proc.max_category_levels': 100,\n",
       "      'proc.skew_threshold': 0.99,\n",
       "      'use_ngram_features': False,\n",
       "      'num_layers': 4,\n",
       "      'hidden_size': 128,\n",
       "      'max_batch_size': 512,\n",
       "      'use_batchnorm': False,\n",
       "      'loss_function': 'auto'},\n",
       "     'hyperparameters_fit': {'batch_size': 32, 'num_epochs': 2},\n",
       "     'hyperparameters_nondefault': ['num_epochs'],\n",
       "     'ag_args_fit': {'max_memory_usage_ratio': 1.0,\n",
       "      'max_time_limit_ratio': 1.0,\n",
       "      'max_time_limit': None,\n",
       "      'min_time_limit': 0,\n",
       "      'valid_raw_types': ['bool', 'int', 'float', 'category'],\n",
       "      'valid_special_types': None,\n",
       "      'ignored_type_group_special': ['text_ngram', 'text_as_category'],\n",
       "      'ignored_type_group_raw': None,\n",
       "      'get_features_kwargs': None,\n",
       "      'get_features_kwargs_extra': None,\n",
       "      'predict_1_batch_size': None},\n",
       "     'num_features': 14,\n",
       "     'features': ['age',\n",
       "      'fnlwgt',\n",
       "      'education-num',\n",
       "      'sex',\n",
       "      'capital-gain',\n",
       "      'capital-loss',\n",
       "      'hours-per-week',\n",
       "      'class',\n",
       "      'workclass',\n",
       "      'education',\n",
       "      'marital-status',\n",
       "      'relationship',\n",
       "      'race',\n",
       "      'native-country'],\n",
       "     'feature_metadata': <autogluon.common.features.feature_metadata.FeatureMetadata at 0x27d2f377190>,\n",
       "     'memory_size': 256186},\n",
       "    'S1F2': {'name': 'S1F2',\n",
       "     'model_type': 'TabularNeuralNetTorchModel',\n",
       "     'problem_type': 'multiclass',\n",
       "     'eval_metric': 'accuracy',\n",
       "     'stopping_metric': 'accuracy',\n",
       "     'fit_time': 0.8247075080871582,\n",
       "     'num_classes': 12,\n",
       "     'quantile_levels': None,\n",
       "     'predict_time': 0.013511180877685547,\n",
       "     'val_score': 0.19387755102040816,\n",
       "     'hyperparameters': {'num_epochs': 2,\n",
       "      'epochs_wo_improve': 20,\n",
       "      'activation': 'relu',\n",
       "      'embedding_size_factor': 1.0,\n",
       "      'embed_exponent': 0.56,\n",
       "      'max_embedding_dim': 100,\n",
       "      'y_range': None,\n",
       "      'y_range_extend': 0.05,\n",
       "      'dropout_prob': 0.1,\n",
       "      'optimizer': 'adam',\n",
       "      'learning_rate': 0.0003,\n",
       "      'weight_decay': 1e-06,\n",
       "      'proc.embed_min_categories': 4,\n",
       "      'proc.impute_strategy': 'median',\n",
       "      'proc.max_category_levels': 100,\n",
       "      'proc.skew_threshold': 0.99,\n",
       "      'use_ngram_features': False,\n",
       "      'num_layers': 4,\n",
       "      'hidden_size': 128,\n",
       "      'max_batch_size': 512,\n",
       "      'use_batchnorm': False,\n",
       "      'loss_function': 'auto'},\n",
       "     'hyperparameters_fit': {'batch_size': 32, 'num_epochs': 2},\n",
       "     'hyperparameters_nondefault': ['num_epochs'],\n",
       "     'ag_args_fit': {'max_memory_usage_ratio': 1.0,\n",
       "      'max_time_limit_ratio': 1.0,\n",
       "      'max_time_limit': None,\n",
       "      'min_time_limit': 0,\n",
       "      'valid_raw_types': ['bool', 'int', 'float', 'category'],\n",
       "      'valid_special_types': None,\n",
       "      'ignored_type_group_special': ['text_ngram', 'text_as_category'],\n",
       "      'ignored_type_group_raw': None,\n",
       "      'get_features_kwargs': None,\n",
       "      'get_features_kwargs_extra': None,\n",
       "      'predict_1_batch_size': None},\n",
       "     'num_features': 14,\n",
       "     'features': ['age',\n",
       "      'fnlwgt',\n",
       "      'education-num',\n",
       "      'sex',\n",
       "      'capital-gain',\n",
       "      'capital-loss',\n",
       "      'hours-per-week',\n",
       "      'class',\n",
       "      'workclass',\n",
       "      'education',\n",
       "      'marital-status',\n",
       "      'relationship',\n",
       "      'race',\n",
       "      'native-country'],\n",
       "     'feature_metadata': <autogluon.common.features.feature_metadata.FeatureMetadata at 0x27d2f377910>,\n",
       "     'memory_size': 255488},\n",
       "    'S1F3': {'name': 'S1F3',\n",
       "     'model_type': 'TabularNeuralNetTorchModel',\n",
       "     'problem_type': 'multiclass',\n",
       "     'eval_metric': 'accuracy',\n",
       "     'stopping_metric': 'accuracy',\n",
       "     'fit_time': 0.8227062225341797,\n",
       "     'num_classes': 12,\n",
       "     'quantile_levels': None,\n",
       "     'predict_time': 0.010509490966796875,\n",
       "     'val_score': 0.1326530612244898,\n",
       "     'hyperparameters': {'num_epochs': 2,\n",
       "      'epochs_wo_improve': 20,\n",
       "      'activation': 'relu',\n",
       "      'embedding_size_factor': 1.0,\n",
       "      'embed_exponent': 0.56,\n",
       "      'max_embedding_dim': 100,\n",
       "      'y_range': None,\n",
       "      'y_range_extend': 0.05,\n",
       "      'dropout_prob': 0.1,\n",
       "      'optimizer': 'adam',\n",
       "      'learning_rate': 0.0003,\n",
       "      'weight_decay': 1e-06,\n",
       "      'proc.embed_min_categories': 4,\n",
       "      'proc.impute_strategy': 'median',\n",
       "      'proc.max_category_levels': 100,\n",
       "      'proc.skew_threshold': 0.99,\n",
       "      'use_ngram_features': False,\n",
       "      'num_layers': 4,\n",
       "      'hidden_size': 128,\n",
       "      'max_batch_size': 512,\n",
       "      'use_batchnorm': False,\n",
       "      'loss_function': 'auto'},\n",
       "     'hyperparameters_fit': {'batch_size': 32, 'num_epochs': 1},\n",
       "     'hyperparameters_nondefault': ['num_epochs'],\n",
       "     'ag_args_fit': {'max_memory_usage_ratio': 1.0,\n",
       "      'max_time_limit_ratio': 1.0,\n",
       "      'max_time_limit': None,\n",
       "      'min_time_limit': 0,\n",
       "      'valid_raw_types': ['bool', 'int', 'float', 'category'],\n",
       "      'valid_special_types': None,\n",
       "      'ignored_type_group_special': ['text_ngram', 'text_as_category'],\n",
       "      'ignored_type_group_raw': None,\n",
       "      'get_features_kwargs': None,\n",
       "      'get_features_kwargs_extra': None,\n",
       "      'predict_1_batch_size': None},\n",
       "     'num_features': 14,\n",
       "     'features': ['age',\n",
       "      'fnlwgt',\n",
       "      'education-num',\n",
       "      'sex',\n",
       "      'capital-gain',\n",
       "      'capital-loss',\n",
       "      'hours-per-week',\n",
       "      'class',\n",
       "      'workclass',\n",
       "      'education',\n",
       "      'marital-status',\n",
       "      'relationship',\n",
       "      'race',\n",
       "      'native-country'],\n",
       "     'feature_metadata': <autogluon.common.features.feature_metadata.FeatureMetadata at 0x27d2f377f10>,\n",
       "     'memory_size': 256186},\n",
       "    'S1F5': {'name': 'S1F5',\n",
       "     'model_type': 'TabularNeuralNetTorchModel',\n",
       "     'problem_type': 'multiclass',\n",
       "     'eval_metric': 'accuracy',\n",
       "     'stopping_metric': 'accuracy',\n",
       "     'fit_time': 0.8312129974365234,\n",
       "     'num_classes': 12,\n",
       "     'quantile_levels': None,\n",
       "     'predict_time': 0.011009931564331055,\n",
       "     'val_score': 0.18556701030927836,\n",
       "     'hyperparameters': {'num_epochs': 2,\n",
       "      'epochs_wo_improve': 20,\n",
       "      'activation': 'relu',\n",
       "      'embedding_size_factor': 1.0,\n",
       "      'embed_exponent': 0.56,\n",
       "      'max_embedding_dim': 100,\n",
       "      'y_range': None,\n",
       "      'y_range_extend': 0.05,\n",
       "      'dropout_prob': 0.1,\n",
       "      'optimizer': 'adam',\n",
       "      'learning_rate': 0.0003,\n",
       "      'weight_decay': 1e-06,\n",
       "      'proc.embed_min_categories': 4,\n",
       "      'proc.impute_strategy': 'median',\n",
       "      'proc.max_category_levels': 100,\n",
       "      'proc.skew_threshold': 0.99,\n",
       "      'use_ngram_features': False,\n",
       "      'num_layers': 4,\n",
       "      'hidden_size': 128,\n",
       "      'max_batch_size': 512,\n",
       "      'use_batchnorm': False,\n",
       "      'loss_function': 'auto'},\n",
       "     'hyperparameters_fit': {'batch_size': 32, 'num_epochs': 2},\n",
       "     'hyperparameters_nondefault': ['num_epochs'],\n",
       "     'ag_args_fit': {'max_memory_usage_ratio': 1.0,\n",
       "      'max_time_limit_ratio': 1.0,\n",
       "      'max_time_limit': None,\n",
       "      'min_time_limit': 0,\n",
       "      'valid_raw_types': ['bool', 'int', 'float', 'category'],\n",
       "      'valid_special_types': None,\n",
       "      'ignored_type_group_special': ['text_ngram', 'text_as_category'],\n",
       "      'ignored_type_group_raw': None,\n",
       "      'get_features_kwargs': None,\n",
       "      'get_features_kwargs_extra': None,\n",
       "      'predict_1_batch_size': None},\n",
       "     'num_features': 14,\n",
       "     'features': ['age',\n",
       "      'fnlwgt',\n",
       "      'education-num',\n",
       "      'sex',\n",
       "      'capital-gain',\n",
       "      'capital-loss',\n",
       "      'hours-per-week',\n",
       "      'class',\n",
       "      'workclass',\n",
       "      'education',\n",
       "      'marital-status',\n",
       "      'relationship',\n",
       "      'race',\n",
       "      'native-country'],\n",
       "     'feature_metadata': <autogluon.common.features.feature_metadata.FeatureMetadata at 0x27d2f3777f0>,\n",
       "     'memory_size': 253106},\n",
       "    'S1F1': {'name': 'S1F1',\n",
       "     'model_type': 'TabularNeuralNetTorchModel',\n",
       "     'problem_type': 'multiclass',\n",
       "     'eval_metric': 'accuracy',\n",
       "     'stopping_metric': 'accuracy',\n",
       "     'fit_time': 0.8322141170501709,\n",
       "     'num_classes': 12,\n",
       "     'quantile_levels': None,\n",
       "     'predict_time': 0.011010169982910156,\n",
       "     'val_score': 0.16326530612244897,\n",
       "     'hyperparameters': {'num_epochs': 2,\n",
       "      'epochs_wo_improve': 20,\n",
       "      'activation': 'relu',\n",
       "      'embedding_size_factor': 1.0,\n",
       "      'embed_exponent': 0.56,\n",
       "      'max_embedding_dim': 100,\n",
       "      'y_range': None,\n",
       "      'y_range_extend': 0.05,\n",
       "      'dropout_prob': 0.1,\n",
       "      'optimizer': 'adam',\n",
       "      'learning_rate': 0.0003,\n",
       "      'weight_decay': 1e-06,\n",
       "      'proc.embed_min_categories': 4,\n",
       "      'proc.impute_strategy': 'median',\n",
       "      'proc.max_category_levels': 100,\n",
       "      'proc.skew_threshold': 0.99,\n",
       "      'use_ngram_features': False,\n",
       "      'num_layers': 4,\n",
       "      'hidden_size': 128,\n",
       "      'max_batch_size': 512,\n",
       "      'use_batchnorm': False,\n",
       "      'loss_function': 'auto'},\n",
       "     'hyperparameters_fit': {'batch_size': 32, 'num_epochs': 2},\n",
       "     'hyperparameters_nondefault': ['num_epochs'],\n",
       "     'ag_args_fit': {'max_memory_usage_ratio': 1.0,\n",
       "      'max_time_limit_ratio': 1.0,\n",
       "      'max_time_limit': None,\n",
       "      'min_time_limit': 0,\n",
       "      'valid_raw_types': ['bool', 'int', 'float', 'category'],\n",
       "      'valid_special_types': None,\n",
       "      'ignored_type_group_special': ['text_ngram', 'text_as_category'],\n",
       "      'ignored_type_group_raw': None,\n",
       "      'get_features_kwargs': None,\n",
       "      'get_features_kwargs_extra': None,\n",
       "      'predict_1_batch_size': None},\n",
       "     'num_features': 14,\n",
       "     'features': ['age',\n",
       "      'fnlwgt',\n",
       "      'education-num',\n",
       "      'sex',\n",
       "      'capital-gain',\n",
       "      'capital-loss',\n",
       "      'hours-per-week',\n",
       "      'class',\n",
       "      'workclass',\n",
       "      'education',\n",
       "      'marital-status',\n",
       "      'relationship',\n",
       "      'race',\n",
       "      'native-country'],\n",
       "     'feature_metadata': <autogluon.common.features.feature_metadata.FeatureMetadata at 0x27d2f3779a0>,\n",
       "     'memory_size': 252512}}},\n",
       "  'WeightedEnsemble_L2': {'name': 'WeightedEnsemble_L2',\n",
       "   'model_type': 'WeightedEnsembleModel',\n",
       "   'problem_type': 'multiclass',\n",
       "   'eval_metric': 'accuracy',\n",
       "   'stopping_metric': 'accuracy',\n",
       "   'fit_time': 0.08857583999633789,\n",
       "   'num_classes': 12,\n",
       "   'quantile_levels': None,\n",
       "   'predict_time': 0.0,\n",
       "   'val_score': 0.3067484662576687,\n",
       "   'hyperparameters': {'use_orig_features': False,\n",
       "    'max_base_models': 25,\n",
       "    'max_base_models_per_type': 5,\n",
       "    'save_bag_folds': True},\n",
       "   'hyperparameters_fit': {},\n",
       "   'hyperparameters_nondefault': ['save_bag_folds'],\n",
       "   'ag_args_fit': {'max_memory_usage_ratio': 1.0,\n",
       "    'max_time_limit_ratio': 1.0,\n",
       "    'max_time_limit': None,\n",
       "    'min_time_limit': 0,\n",
       "    'valid_raw_types': None,\n",
       "    'valid_special_types': None,\n",
       "    'ignored_type_group_special': None,\n",
       "    'ignored_type_group_raw': None,\n",
       "    'get_features_kwargs': None,\n",
       "    'get_features_kwargs_extra': None,\n",
       "    'predict_1_batch_size': None,\n",
       "    'drop_unique': False},\n",
       "   'num_features': 12,\n",
       "   'features': ['LightGBM_BAG_L1_8',\n",
       "    'LightGBM_BAG_L1_9',\n",
       "    'LightGBM_BAG_L1_3',\n",
       "    'LightGBM_BAG_L1_2',\n",
       "    'LightGBM_BAG_L1_7',\n",
       "    'LightGBM_BAG_L1_4',\n",
       "    'LightGBM_BAG_L1_5',\n",
       "    'LightGBM_BAG_L1_10',\n",
       "    'LightGBM_BAG_L1_0',\n",
       "    'LightGBM_BAG_L1_11',\n",
       "    'LightGBM_BAG_L1_6',\n",
       "    'LightGBM_BAG_L1_1'],\n",
       "   'feature_metadata': <autogluon.common.features.feature_metadata.FeatureMetadata at 0x27d2f3dfac0>,\n",
       "   'memory_size': 4448,\n",
       "   'bagged_info': {'child_model_type': 'GreedyWeightedEnsembleModel',\n",
       "    'num_child_models': 1,\n",
       "    'child_model_names': ['S1F1'],\n",
       "    '_n_repeats': 1,\n",
       "    '_k_per_n_repeat': [1],\n",
       "    '_random_state': 2,\n",
       "    'low_memory': False,\n",
       "    'bagged_mode': False,\n",
       "    'max_memory_size': 4448,\n",
       "    'min_memory_size': 4448,\n",
       "    'child_hyperparameters': {'ensemble_size': 100},\n",
       "    'child_hyperparameters_fit': {'ensemble_size': 1},\n",
       "    'child_ag_args_fit': {'max_memory_usage_ratio': 1.0,\n",
       "     'max_time_limit_ratio': 1.0,\n",
       "     'max_time_limit': None,\n",
       "     'min_time_limit': 0,\n",
       "     'valid_raw_types': None,\n",
       "     'valid_special_types': None,\n",
       "     'ignored_type_group_special': None,\n",
       "     'ignored_type_group_raw': None,\n",
       "     'get_features_kwargs': None,\n",
       "     'get_features_kwargs_extra': None,\n",
       "     'predict_1_batch_size': None,\n",
       "     'drop_unique': False}},\n",
       "   'stacker_info': {'num_base_models': 1,\n",
       "    'base_model_names': ['LightGBM_BAG_L1']},\n",
       "   'children_info': {'S1F1': {'name': 'S1F1',\n",
       "     'model_type': 'GreedyWeightedEnsembleModel',\n",
       "     'problem_type': 'multiclass',\n",
       "     'eval_metric': 'accuracy',\n",
       "     'stopping_metric': 'accuracy',\n",
       "     'fit_time': 0.08857583999633789,\n",
       "     'num_classes': 12,\n",
       "     'quantile_levels': None,\n",
       "     'predict_time': None,\n",
       "     'val_score': None,\n",
       "     'hyperparameters': {'ensemble_size': 100},\n",
       "     'hyperparameters_fit': {'ensemble_size': 1},\n",
       "     'hyperparameters_nondefault': [],\n",
       "     'ag_args_fit': {'max_memory_usage_ratio': 1.0,\n",
       "      'max_time_limit_ratio': 1.0,\n",
       "      'max_time_limit': None,\n",
       "      'min_time_limit': 0,\n",
       "      'valid_raw_types': None,\n",
       "      'valid_special_types': None,\n",
       "      'ignored_type_group_special': None,\n",
       "      'ignored_type_group_raw': None,\n",
       "      'get_features_kwargs': None,\n",
       "      'get_features_kwargs_extra': None,\n",
       "      'predict_1_batch_size': None,\n",
       "      'drop_unique': False},\n",
       "     'num_features': 12,\n",
       "     'features': ['LightGBM_BAG_L1_0',\n",
       "      'LightGBM_BAG_L1_1',\n",
       "      'LightGBM_BAG_L1_2',\n",
       "      'LightGBM_BAG_L1_3',\n",
       "      'LightGBM_BAG_L1_4',\n",
       "      'LightGBM_BAG_L1_5',\n",
       "      'LightGBM_BAG_L1_6',\n",
       "      'LightGBM_BAG_L1_7',\n",
       "      'LightGBM_BAG_L1_8',\n",
       "      'LightGBM_BAG_L1_9',\n",
       "      'LightGBM_BAG_L1_10',\n",
       "      'LightGBM_BAG_L1_11'],\n",
       "     'feature_metadata': <autogluon.common.features.feature_metadata.FeatureMetadata at 0x27d2f3df6d0>,\n",
       "     'memory_size': 6310,\n",
       "     'model_weights': {'LightGBM_BAG_L1': 1.0}}}}}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LAbWBTpjrjNV"
   },
   "source": [
    "Nasz `predictor` również pamięta, którą metryką jest ewaluowany."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "0RAFXQgJrjNV",
    "outputId": "a9dd30d0-be63-4794-d59b-79a712270f4d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: accuracy on test data: 0.28161040050325015\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"accuracy\": 0.28161040050325015,\n",
      "    \"balanced_accuracy\": 0.17153608484671554,\n",
      "    \"mcc\": 0.18968536606951916\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = predictor.predict_proba(test_data_nolabel)\n",
    "perf = predictor.evaluate_predictions(y_true=y_test, y_pred=y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "xXYoAf8OrjNV",
    "outputId": "04dda9b2-0527-4e72-87d1-e09f6eabb350",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: accuracy on test data: 0.28161040050325015\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"accuracy\": 0.28161040050325015,\n",
      "    \"balanced_accuracy\": 0.17153608484671554,\n",
      "    \"mcc\": 0.18968536606951916\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "perf = predictor.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Yy2CMnerjNW"
   },
   "source": [
    "## Interpretowalność"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EAmpeescrjNW"
   },
   "source": [
    "Możemy sprawdzić wpływ poszczególnych zmiennych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "Trldx3ysrjNW",
    "outputId": "9cc13c84-a0cd-41cd-ba4b-1738c72be64d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 14 features using 1000 rows with 3 shuffle sets...\n",
      "\t2.88s\t= Expected runtime (0.96s per shuffle set)\n",
      "\t0.66s\t= Actual runtime (Completed 3 of 3 shuffle sets)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>p_value</th>\n",
       "      <th>n</th>\n",
       "      <th>p99_high</th>\n",
       "      <th>p99_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>education-num</th>\n",
       "      <td>0.073667</td>\n",
       "      <td>0.013577</td>\n",
       "      <td>0.005567</td>\n",
       "      <td>3</td>\n",
       "      <td>0.151464</td>\n",
       "      <td>-0.004131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>0.039333</td>\n",
       "      <td>0.010693</td>\n",
       "      <td>0.011880</td>\n",
       "      <td>3</td>\n",
       "      <td>0.100604</td>\n",
       "      <td>-0.021937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>workclass</th>\n",
       "      <td>0.036000</td>\n",
       "      <td>0.005196</td>\n",
       "      <td>0.003436</td>\n",
       "      <td>3</td>\n",
       "      <td>0.065775</td>\n",
       "      <td>0.006225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hours-per-week</th>\n",
       "      <td>0.035667</td>\n",
       "      <td>0.010504</td>\n",
       "      <td>0.013857</td>\n",
       "      <td>3</td>\n",
       "      <td>0.095856</td>\n",
       "      <td>-0.024522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.024333</td>\n",
       "      <td>0.026006</td>\n",
       "      <td>0.123271</td>\n",
       "      <td>3</td>\n",
       "      <td>0.173353</td>\n",
       "      <td>-0.124686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.007767</td>\n",
       "      <td>0.048476</td>\n",
       "      <td>3</td>\n",
       "      <td>0.057842</td>\n",
       "      <td>-0.031175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fnlwgt</th>\n",
       "      <td>0.012333</td>\n",
       "      <td>0.019655</td>\n",
       "      <td>0.195326</td>\n",
       "      <td>3</td>\n",
       "      <td>0.124961</td>\n",
       "      <td>-0.100294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education</th>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.037090</td>\n",
       "      <td>3</td>\n",
       "      <td>0.007730</td>\n",
       "      <td>-0.003730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relationship</th>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.007211</td>\n",
       "      <td>0.339183</td>\n",
       "      <td>3</td>\n",
       "      <td>0.043320</td>\n",
       "      <td>-0.039320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital-gain</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.112702</td>\n",
       "      <td>3</td>\n",
       "      <td>0.006730</td>\n",
       "      <td>-0.004730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital-loss</th>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.001155</td>\n",
       "      <td>0.211325</td>\n",
       "      <td>3</td>\n",
       "      <td>0.007283</td>\n",
       "      <td>-0.005950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marital-status</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>native-country</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                importance    stddev   p_value  n  p99_high   p99_low\n",
       "education-num     0.073667  0.013577  0.005567  3  0.151464 -0.004131\n",
       "sex               0.039333  0.010693  0.011880  3  0.100604 -0.021937\n",
       "workclass         0.036000  0.005196  0.003436  3  0.065775  0.006225\n",
       "hours-per-week    0.035667  0.010504  0.013857  3  0.095856 -0.024522\n",
       "age               0.024333  0.026006  0.123271  3  0.173353 -0.124686\n",
       "class             0.013333  0.007767  0.048476  3  0.057842 -0.031175\n",
       "fnlwgt            0.012333  0.019655  0.195326  3  0.124961 -0.100294\n",
       "education         0.002000  0.001000  0.037090  3  0.007730 -0.003730\n",
       "relationship      0.002000  0.007211  0.339183  3  0.043320 -0.039320\n",
       "capital-gain      0.001000  0.001000  0.112702  3  0.006730 -0.004730\n",
       "capital-loss      0.000667  0.001155  0.211325  3  0.007283 -0.005950\n",
       "marital-status    0.000000  0.000000  0.500000  3  0.000000  0.000000\n",
       "race              0.000000  0.000000  0.500000  3  0.000000  0.000000\n",
       "native-country    0.000000  0.000000  0.500000  3  0.000000  0.000000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.feature_importance(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t5G__T1DrjNW"
   },
   "source": [
    "## Zmniejszanie czasu potrzebnego do wykonania predykcji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kYsSvOt2rjNW"
   },
   "source": [
    "![](optymalizacja.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "osXA8ofHrjNW"
   },
   "source": [
    "Jeżeli baggin jest włączony (num_bag_folds>0 lub num_stack_levels>0 lub używamy ‘best_quality’ preset), powinniśmy optymalizować w takiej kolejności:\n",
    "1. refit_full\n",
    "2. persist_models\n",
    "3. infer_limit\n",
    "\n",
    "\n",
    "Jeżeli bagging jest wyłączony (num_bag_folds=0, num_stack_levels=0), powinniśmy optymalizować w takiej kolejności:\n",
    "1. persist_models\n",
    "2. infer_limit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ts7wN5QorjNW"
   },
   "source": [
    "## Przechowywanie modeli w pamięci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p8G3-V5QrjNW"
   },
   "source": [
    "Domyślnie AutoGluon ładuje modele do pamięci pojedynczo i tylko wtedy, gdy są potrzebne do predykcji. Ta strategia jest niezawodna w przypadku *stacked/bagged ensembles*, ale prowadzi do wolniejszych czasów przewidywania. Jeśli planujesz powtarzać prognozy (np. dla nowych punktów danych pojedynczo, a nie jednego dużego testowego zestawu danych), możesz najpierw określić, że wszystkie modele wymagane do wnioskowania powinny być ładowane do pamięci w następujący sposób:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "Sc82QpVurjNX",
    "outputId": "57fcc3a5-8d27-4242-ac54-ddba55f6f690"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Persisting 2 models in memory. Models will require 0.01% of memory.\n",
      "Evaluation: accuracy on test data: 0.25\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"accuracy\": 0.25,\n",
      "    \"balanced_accuracy\": 0.3208333333333336,\n",
      "    \"mcc\": 0.12316635631735146\n",
      "}\n",
      "Unpersisted 2 models: ['WeightedEnsemble_L2', 'LightGBM_BAG_L1']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:  [' Exec-managerial' ' Sales' ' Craft-repair' ' ?' ' ?' ' Exec-managerial'\n",
      " ' Exec-managerial' ' Sales' ' Exec-managerial' ' Adm-clerical'\n",
      " ' Other-service' ' Exec-managerial' ' Exec-managerial' ' Exec-managerial'\n",
      " ' Adm-clerical' ' ?' ' Craft-repair' ' Craft-repair' ' Exec-managerial'\n",
      " ' Craft-repair']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['WeightedEnsemble_L2', 'LightGBM_BAG_L1']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.persist_models()\n",
    "\n",
    "num_test = 20\n",
    "preds = np.array(['']*num_test, dtype='object')\n",
    "for i in range(num_test):\n",
    "    datapoint = test_data_nolabel.iloc[[i]]\n",
    "    pred_numpy = predictor.predict(datapoint, as_pandas=False)\n",
    "    preds[i] = pred_numpy[0]\n",
    "\n",
    "perf = predictor.evaluate_predictions(y_test[:num_test], preds, auxiliary_metrics=True)\n",
    "print(\"Predictions: \", preds)\n",
    "\n",
    "predictor.unpersist_models()  # zwalnianie pamięci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P36evCRdrjNX"
   },
   "source": [
    "## Szybsze presety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "wF4y67sYrjNX",
    "outputId": "8f86af88-cd7c-4840-8c28-89803756ff50",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20220406_182927\\\"\n",
      "Presets specified: ['good_quality', 'optimize_for_deployment']\n",
      "Beginning AutoGluon training ... Time limit = 30s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20220406_182927\\\"\n",
      "AutoGluon Version:  0.4.0\n",
      "Python Version:     3.9.7\n",
      "Operating System:   Windows\n",
      "Train Data Rows:    500\n",
      "Train Data Columns: 14\n",
      "Label Column: occupation\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\tFirst 10 (of 15) unique label values:  [' Exec-managerial', ' Other-service', ' Craft-repair', ' Sales', ' Prof-specialty', ' Protective-serv', ' ?', ' Adm-clerical', ' Machine-op-inspct', ' Tech-support']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 12 out of 15 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.978\n",
      "Train Data Class Count: 12\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    7708.85 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.28 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'relationship', 'race', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 6 | ['workclass', 'education', 'marital-status', 'relationship', 'race', ...]\n",
      "\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('int', ['bool']) : 2 | ['sex', 'class']\n",
      "\t0.1s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.09s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 29.91s of the 29.9s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.3088\t = Validation score   (accuracy)\n",
      "\t2.74s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 20.71s of the 20.71s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.3497\t = Validation score   (accuracy)\n",
      "\t1.72s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 12.56s of the 12.56s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.3395\t = Validation score   (accuracy)\n",
      "\t1.98s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 3.99s of the 3.99s of remaining time.\n",
      "\t0.2986\t = Validation score   (accuracy)\n",
      "\t0.45s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 3.4s of the 3.39s of remaining time.\n",
      "\t0.3067\t = Validation score   (accuracy)\n",
      "\t0.37s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 2.89s of the 2.88s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.3067\t = Validation score   (accuracy)\n",
      "\t2.17s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 29.91s of the -6.21s of remaining time.\n",
      "\t0.3497\t = Validation score   (accuracy)\n",
      "\t0.19s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 36.42s ... Best model: \"WeightedEnsemble_L2\"\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\t0.46s\t = Training   runtime\n",
      "Deleting model NeuralNetFastAI_BAG_L1. All files under AutogluonModels/ag-20220406_182927\\models\\NeuralNetFastAI_BAG_L1\\ will be removed.\n",
      "Deleting model LightGBMXT_BAG_L1. All files under AutogluonModels/ag-20220406_182927\\models\\LightGBMXT_BAG_L1\\ will be removed.\n",
      "Deleting model LightGBM_BAG_L1. All files under AutogluonModels/ag-20220406_182927\\models\\LightGBM_BAG_L1\\ will be removed.\n",
      "Deleting model RandomForestGini_BAG_L1. All files under AutogluonModels/ag-20220406_182927\\models\\RandomForestGini_BAG_L1\\ will be removed.\n",
      "Deleting model RandomForestEntr_BAG_L1. All files under AutogluonModels/ag-20220406_182927\\models\\RandomForestEntr_BAG_L1\\ will be removed.\n",
      "Deleting model CatBoost_BAG_L1. All files under AutogluonModels/ag-20220406_182927\\models\\CatBoost_BAG_L1\\ will be removed.\n",
      "Deleting model WeightedEnsemble_L2. All files under AutogluonModels/ag-20220406_182927\\models\\WeightedEnsemble_L2\\ will be removed.\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220406_182927\\\")\n"
     ]
    }
   ],
   "source": [
    "presets = ['good_quality', 'optimize_for_deployment']\n",
    "predictor_light = TabularPredictor(label=label, eval_metric=metric).fit(train_data, presets=presets, time_limit=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "70PvEtQirjNX"
   },
   "source": [
    "Preset `very_light` i `light`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "svPpi4SsrjNX",
    "outputId": "bd9aadbb-e64f-42cd-936c-4a013a14f582",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20220406_183004\\\"\n",
      "Beginning AutoGluon training ... Time limit = 30s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20220406_183004\\\"\n",
      "AutoGluon Version:  0.4.0\n",
      "Python Version:     3.9.7\n",
      "Operating System:   Windows\n",
      "Train Data Rows:    500\n",
      "Train Data Columns: 14\n",
      "Label Column: occupation\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\tFirst 10 (of 15) unique label values:  [' Exec-managerial', ' Other-service', ' Craft-repair', ' Sales', ' Prof-specialty', ' Protective-serv', ' ?', ' Adm-clerical', ' Machine-op-inspct', ' Tech-support']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 12 out of 15 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.978\n",
      "Train Data Class Count: 12\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    7651.57 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.28 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'relationship', 'race', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 6 | ['workclass', 'education', 'marital-status', 'relationship', 'race', ...]\n",
      "\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('int', ['bool']) : 2 | ['sex', 'class']\n",
      "\t0.1s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.1s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 391, Val Rows: 98\n",
      "Fitting 7 L1 models ...\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 29.9s of the 29.9s of remaining time.\n",
      "\t0.3061\t = Validation score   (accuracy)\n",
      "\t0.53s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 29.35s of the 29.35s of remaining time.\n",
      "\t0.3571\t = Validation score   (accuracy)\n",
      "\t0.7s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 28.61s of the 28.61s of remaining time.\n",
      "\t0.3673\t = Validation score   (accuracy)\n",
      "\t1.02s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 27.58s of the 27.58s of remaining time.\n",
      "\tRan out of time, early stopping on iteration 392.\n",
      "\t0.3469\t = Validation score   (accuracy)\n",
      "\t27.47s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 0.1s of the 0.09s of remaining time.\n",
      "\t0.398\t = Validation score   (accuracy)\n",
      "\t0.16s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 29.9s of the -0.18s of remaining time.\n",
      "\t0.398\t = Validation score   (accuracy)\n",
      "\t0.11s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 30.32s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220406_183004\\\")\n"
     ]
    }
   ],
   "source": [
    "predictor_light = TabularPredictor(label=label, eval_metric=metric).fit(train_data, hyperparameters='very_light', time_limit=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ls9TRnPErjNX"
   },
   "source": [
    "**Możemy również wykluczyć modele, które mają długi czas trenowania.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "jBdg7_6xrjNX",
    "outputId": "b70e0df4-ee2f-4a52-c2df-0dfd359dd4b1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20220406_183034\\\"\n",
      "Beginning AutoGluon training ... Time limit = 30s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20220406_183034\\\"\n",
      "AutoGluon Version:  0.4.0\n",
      "Python Version:     3.9.7\n",
      "Operating System:   Windows\n",
      "Train Data Rows:    500\n",
      "Train Data Columns: 14\n",
      "Label Column: occupation\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\tFirst 10 (of 15) unique label values:  [' Exec-managerial', ' Other-service', ' Craft-repair', ' Sales', ' Prof-specialty', ' Protective-serv', ' ?', ' Adm-clerical', ' Machine-op-inspct', ' Tech-support']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 12 out of 15 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.978\n",
      "Train Data Class Count: 12\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    7540.54 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.28 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'relationship', 'race', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 6 | ['workclass', 'education', 'marital-status', 'relationship', 'race', ...]\n",
      "\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('int', ['bool']) : 2 | ['sex', 'class']\n",
      "\t0.1s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.09s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 391, Val Rows: 98\n",
      "Excluded Model Types: ['KNN', 'NN_TORCH', 'custom']\n",
      "\tFound 'NN_TORCH' model in hyperparameters, but 'NN_TORCH' is present in `excluded_model_types` and will be removed.\n",
      "\tFound 'KNN' model in hyperparameters, but 'KNN' is present in `excluded_model_types` and will be removed.\n",
      "\tFound 'KNN' model in hyperparameters, but 'KNN' is present in `excluded_model_types` and will be removed.\n",
      "Fitting 10 L1 models ...\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 29.91s of the 29.91s of remaining time.\n",
      "\t0.3061\t = Validation score   (accuracy)\n",
      "\t0.48s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 29.41s of the 29.4s of remaining time.\n",
      "\t0.3571\t = Validation score   (accuracy)\n",
      "\t0.72s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 28.66s of the 28.65s of remaining time.\n",
      "\t0.3673\t = Validation score   (accuracy)\n",
      "\t0.94s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ... Training model for up to 27.7s of the 27.69s of remaining time.\n",
      "\t0.2959\t = Validation score   (accuracy)\n",
      "\t0.37s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ... Training model for up to 27.25s of the 27.25s of remaining time.\n",
      "\t0.2959\t = Validation score   (accuracy)\n",
      "\t0.35s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 26.83s of the 26.83s of remaining time.\n",
      "\tRan out of time, early stopping on iteration 391.\n",
      "\t0.3469\t = Validation score   (accuracy)\n",
      "\t26.72s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ... Training model for up to 0.1s of the 0.09s of remaining time.\n",
      "\tWarning: Model is expected to require 0.8s to train, which exceeds the maximum time limit of 0.1s, skipping model...\n",
      "\tTime limit exceeded... Skipping ExtraTreesGini.\n",
      "Fitting model: ExtraTreesEntr ... Training model for up to 0.08s of the 0.07s of remaining time.\n",
      "\tWarning: Model is expected to require 0.7s to train, which exceeds the maximum time limit of 0.1s, skipping model...\n",
      "\tTime limit exceeded... Skipping ExtraTreesEntr.\n",
      "Fitting model: XGBoost ... Training model for up to 0.06s of the 0.05s of remaining time.\n",
      "\t0.398\t = Validation score   (accuracy)\n",
      "\t0.09s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 29.91s of the -0.35s of remaining time.\n",
      "\t0.398\t = Validation score   (accuracy)\n",
      "\t0.14s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 30.52s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220406_183034\\\")\n"
     ]
    }
   ],
   "source": [
    "excluded_model_types = ['KNN', 'NN_TORCH']\n",
    "predictor_light = TabularPredictor(label=label, eval_metric=metric).fit(train_data, excluded_model_types=excluded_model_types, time_limit=30)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Prezentacja",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "autogluon",
   "language": "python",
   "name": "autogluon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
