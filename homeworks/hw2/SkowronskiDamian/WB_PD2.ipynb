{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Damian Skowroński | Warszaty badawcze | Praca domowa 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wczytanie przetworzonych danych z pierwszej pracy domowej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"PD1_data.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W początkowej ramce danych zmienna _readmitted_ miała trzy możliwe wartości \"NO\",\">30\" i \"<30\". Po przetworzeniu danych w pracy domowej 1 te wartości mają wartości odpowiednio 2 ,1 ,0. Teraz zamieniam je, żeby była to zmienna binarna o wartościach 0 lub 1. gdzie 0 oznacza, że pacjent był ponownie przyjęty, a 1 oznacza, że nie był.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    52338\n",
       "1    45715\n",
       "Name: readmitted, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"readmitted\"] = df[\"readmitted\"].apply(lambda x: 0 if x == 2 else 1)\n",
    "df.readmitted.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dodatkowo wykonam encoding zmiennych _diag_1_, _diag_2_ i _diag_3_, używając Label Encoding, ponieważ nie zrobiłem tego wcześniej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "for col in [\"diag_1\",\"diag_2\",\"diag_3\"]:\n",
    "    df[col] = label_encoder.fit_transform(df[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podział zbioru na zbiory treningowe i testowe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.loc[:,df.columns != \"readmitted\"], df[\"readmitted\"], test_size = 0.25, random_state=123\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Użyję modelu _Random Forest Classifier_. Na początku dla domyślnych parametrów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "default_model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Używam _cross validatoin_ dla z podziałem na 10 zbiorów. Jako metryki stosuję _AOC_ i _F1_. Piszę funkcję printującą wyniki."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "def get_scores(model):\n",
    "    cv = cross_validate(default_model,X_train,y_train,cv = 5,scoring = [\"roc_auc\",\"f1\"])\n",
    "    print(\"AUC = \",max(cv[\"test_roc_auc\"]),\"\\nF1 = \", max(cv[\"test_f1\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I liczę dla modelu domyślego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC =  0.6853062922708105 \n",
      "F1 =  0.5772012578616352\n"
     ]
    }
   ],
   "source": [
    "get_scores(default_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ręczne dobieranie hiperparametrów\n",
    "\n",
    "Z szybkiego researchu wygląda na to, że potencjalnymi parametrami, które mogą mieć duży wpływ na model są:\n",
    "\n",
    "*   n_estimators\n",
    "*   criterion\n",
    "*   max_depth\n",
    "*   min_samples_split\n",
    "*   max_samples_leaf\n",
    "*   max_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sprawdzam dla różnych wartości parametru _n_estimators_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dla n_estimators =  10 :\n",
      "AUC =  0.6836949353068168 \n",
      "F1 =  0.5760436987904799\n",
      "Dla n_estimators =  50 :\n",
      "AUC =  0.6869140094917441 \n",
      "F1 =  0.581761252446184\n",
      "Dla n_estimators =  200 :\n",
      "AUC =  0.6836775815318694 \n",
      "F1 =  0.5788150243595788\n",
      "Dla n_estimators =  500 :\n",
      "AUC =  0.6854796628892262 \n",
      "F1 =  0.5767054385413392\n"
     ]
    }
   ],
   "source": [
    "for val in [10,50,200,500]: #domyślnie jest 100\n",
    "    rfc = RandomForestClassifier(n_estimators=val)\n",
    "    print(\"Dla n_estimators = \", val, \":\")\n",
    "    get_scores(rfc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wynik okazał się najlepszy dla _n_estimators_ = 50, jednak nie jest to jakas duża zmiana względem modelu domyślego. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sprawdzam dla parametru _criterion_, które domyślnie jest jako \"gini\", a może przyjąć też wartość \"entropy\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC =  0.6853194677692859 \n",
      "F1 =  0.5762310606060606\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(criterion=\"entropy\")\n",
    "get_scores(rfc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metryki są bardzo podobne do domyślnego modelu, i czas wykonania jest taki sam więc myślę, że nie warto się zajmować tym parametrem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sprawdzam dla parametru _max_depth_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dla max_depth =  5 :\n",
      "AUC =  0.6864054389646194 \n",
      "F1 =  0.5773907586098691\n",
      "\n",
      "Dla max_depth =  10 :\n",
      "AUC =  0.686005986448828 \n",
      "F1 =  0.5808331364674384\n",
      "\n",
      "Dla max_depth =  15 :\n",
      "AUC =  0.6860584284610823 \n",
      "F1 =  0.576173845556849\n",
      "\n",
      "Dla max_depth =  30 :\n",
      "AUC =  0.6831955477028717 \n",
      "F1 =  0.5734795298572217\n",
      "\n",
      "Dla max_depth =  50 :\n",
      "AUC =  0.6868356343101865 \n",
      "F1 =  0.574254292269958\n"
     ]
    }
   ],
   "source": [
    "for val in [5,10,15,30,50]: #default = None\n",
    "    rfc = RandomForestClassifier(max_depth=val)\n",
    "    print(\"\\nDla max_depth = \",val, \":\")\n",
    "    get_scores(rfc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wartości są znowu bardzo podobne. AUC najlepiej wyszło dla _max_depth_ = 50, ale dobrym wynikiem jest też dla _max_depth_ = 5\n",
    "\n",
    "Sprawdzam dla _min_samples_split_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dla min_samples_split =  4 :\n",
      "AUC =  0.6864417342595737 \n",
      "F1 =  0.575201644788866\n",
      "\n",
      "Dla min_samples_split =  6 :\n",
      "AUC =  0.6851776199255877 \n",
      "F1 =  0.5761589403973509\n",
      "\n",
      "Dla min_samples_split =  8 :\n",
      "AUC =  0.6852861436931562 \n",
      "F1 =  0.5756545123783912\n"
     ]
    }
   ],
   "source": [
    "for val in range(4,11,2): #default = 2\n",
    "    rfc = RandomForestClassifier(min_samples_split=val)\n",
    "    print(\"\\nDla min_samples_split = \",val, \":\")\n",
    "    get_scores(rfc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Znowu zmiana dla AUC nie wydaje się duża. Najlepsze AUC jest dla _min_samples_split_ = 4, a reszta wyników jest gorsza niż dla domyślej wartości."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sprawdzam dla _min_samples_leaf_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dla min_samples_split =  2 :\n",
      "AUC =  0.6857956612962813 \n",
      "F1 =  0.5761407366684992\n",
      "\n",
      "Dla min_samples_split =  4 :\n",
      "AUC =  0.6860142687213016 \n",
      "F1 =  0.575521448248721\n",
      "\n",
      "Dla min_samples_split =  6 :\n",
      "AUC =  0.6857977875747527 \n",
      "F1 =  0.5796418473138549\n",
      "\n",
      "Dla min_samples_split =  8 :\n",
      "AUC =  0.6849891053762256 \n",
      "F1 =  0.5772351319417094\n",
      "\n",
      "Dla min_samples_split =  10 :\n",
      "AUC =  0.6875698781920989 \n",
      "F1 =  0.5789348737833347\n"
     ]
    }
   ],
   "source": [
    "for val in range(2,11,2): #default = 1\n",
    "    rfc = RandomForestClassifier(min_samples_leaf=val)\n",
    "    print(\"\\nDla min_samples_split = \",val, \":\")\n",
    "    get_scores(rfc)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Po raz kolejny zmienna nie wydaje się mieć dużego wpływu na wyniki."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podsumowując, podczas ręcznego sprawdzania, nie znalazłem parametrów, któe mocno by się wyróżniały pod względem otrzymywanych wyników."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Szukanie hiperparametrów używając _random search_, _grid search_ i _optymalizacji bayesowskiej_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "randomized = RandomizedSearchCV(model,param_distributions={\n",
    "    \"n_estimators\" : randint(50,500),\n",
    "    \"min_samples_split\" : randint(3,10),\n",
    "    \"max_depth\" : randint(10,20)\n",
    "}, n_jobs=-1)\n",
    "\n",
    "cv_randomized = cross_validate(randomized,X_train,y_train,cv = 5,scoring = [\"roc_auc\",\"f1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Najlepszy otrzymany wynik AUC wynosi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.696258669111237"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(cv_randomized[\"test_roc_auc\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Grid Search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={'max_depth': [10, 15], 'min_samples_split': [4, 10],\n",
       "                         'n_estimators': [50, 500, 1000]},\n",
       "             scoring='roc_auc')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "grid = GridSearchCV(model, param_grid={\n",
    "    'n_estimators': [50, 500, 1000], \n",
    "    'min_samples_split': [4,10],\n",
    "    'max_depth': [10,15]\n",
    "    }, n_jobs=-1, cv = 5,scoring=\"roc_auc\")\n",
    "\n",
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Najlepszy wynik AUC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.691885674128556"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dla parametrów:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=15, min_samples_split=10, n_estimators=500)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Optymalizacja Bayesowska"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\skdam\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "C:\\Users\\skdam\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "C:\\Users\\skdam\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "C:\\Users\\skdam\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BayesSearchCV(cv=5, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "              scoring='roc_auc',\n",
       "              search_spaces={'max_depth': Integer(low=10, high=20, prior='uniform', transform='normalize'),\n",
       "                             'min_samples_split': Integer(low=3, high=10, prior='uniform', transform='normalize'),\n",
       "                             'n_estimators': Integer(low=50, high=500, prior='uniform', transform='normalize')})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Integer\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "bayes = BayesSearchCV(model,search_spaces={\n",
    "    \"n_estimators\" : Integer(50,500),\n",
    "    \"min_samples_split\" : Integer(3,10),\n",
    "    \"max_depth\" : Integer(10,20)\n",
    "},n_jobs=-1,cv = 5,scoring=\"roc_auc\")\n",
    "\n",
    "bayes.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=18, min_samples_split=10, n_estimators=500)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6918972568649056"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Podsumowanie\n",
    "Już w trakcie ręcznego dopasowywania parametrów, często otrzymywałem wynik AUC lepszy niż dla domyślnego modelu. Spośród algorytmów automatycznie dobierających parametry najlepszy wyszedł dla _random search_, a dla _grid search_ i _optymalizacji bayesa_ wyszło bardzo podobnie, z tym że ta druga działała 2 razy dłużej. Wyniki pomiędzy domyślnym modelem, a najlepszymi jakie udało mi się otrzymać, niewiele się różnią, bo o około 0.01."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "df2beab871ce3a7c6acb66860c4feefeda1abd22eceafa0f5dcbc757af2aa582"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
