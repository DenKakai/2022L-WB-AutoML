{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd958d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "238a2052",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dane bez encodingu z poprzedniego etapu\n",
    "data = pd.read_csv(\"./out.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f14b7ac",
   "metadata": {},
   "source": [
    "## Encoding labelowy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976dbda9",
   "metadata": {},
   "source": [
    "Labelowy, bo nie będzie dużo kolumn co nie spowolni szkolenia modeli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dc4cf738",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = data.select_dtypes(include=['object'])\n",
    "temp = temp.astype('category')\n",
    "for col in temp.columns:\n",
    "    data[col] = temp[col].cat.codes\n",
    "    \n",
    "train_X = data.drop(columns=[\"readmitted\"])\n",
    "train_y = data[\"readmitted\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b8c77acf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    52337\n",
       "1    45715\n",
       "Name: readmitted, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#zamiana na binarne\n",
    "data.loc[data['readmitted'] == 0, 'readmitted'] = 1\n",
    "data.loc[data['readmitted'] == 2, 'readmitted'] = 0\n",
    "#1 oznacza, ze byl w szpitalu, 0 ze nie wrocil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b156b185",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "import scipy.stats\n",
    "import scipy, skopt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5149d895",
   "metadata": {},
   "source": [
    "## Domyślne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "66d516b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3691           11.84s\n",
      "         2           1.3587           11.71s\n",
      "         3           1.3502           11.86s\n",
      "         4           1.3432           12.06s\n",
      "         5           1.3374           11.90s\n",
      "         6           1.3325           11.75s\n",
      "         7           1.3283           11.55s\n",
      "         8           1.3247           11.40s\n",
      "         9           1.3217           11.21s\n",
      "        10           1.3189           11.22s\n",
      "        20           1.3002            9.90s\n",
      "        30           1.2871            8.51s\n",
      "        40           1.2793            7.23s\n",
      "        50           1.2736            5.98s\n",
      "        60           1.2695            4.76s\n",
      "        70           1.2659            3.56s\n",
      "        80           1.2631            2.37s\n",
      "        90           1.2607            1.18s\n",
      "       100           1.2581            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(random_state=0, verbose=True)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model0 = GradientBoostingClassifier(random_state=0, verbose=True)\n",
    "model0.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "268e1f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6284985516852621"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(train_y, model0.predict(train_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ada33b88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6376310529107004"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(train_y, model0.predict(train_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f80c5c2",
   "metadata": {},
   "source": [
    "## Ręczne"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96243bf",
   "metadata": {},
   "source": [
    "Szczerze, nie wiem czy jest tutaj wymagane sprawdzenie dużej ilości przypadków, raczej zostawię to na randomsearch oraz na gridsearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aef0766e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3366            4.45s\n",
      "         2           1.3303            4.45s\n",
      "         3           1.3242            4.35s\n",
      "         4           1.3184            4.33s\n",
      "         5           1.3141            4.27s\n",
      "         6           1.3116            4.19s\n",
      "         7           1.3091            4.13s\n",
      "         8           1.3072            4.10s\n",
      "         9           1.3040            4.04s\n",
      "        10           1.3014            3.99s\n",
      "        20           1.2897            3.57s\n",
      "        30           1.2839            3.13s\n",
      "        40           1.2794            2.67s\n",
      "        50           1.2765            2.26s\n",
      "        60           1.2740            1.80s\n",
      "        70           1.2720            1.35s\n",
      "        80           1.2700            0.90s\n",
      "        90           1.2687            0.45s\n",
      "       100           1.2677            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(learning_rate=1.0, max_depth=1, random_state=0,\n",
       "                           verbose=True)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0, verbose=True)\n",
    "model1.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d2a98d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6238769904506942"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(train_y, model1.predict(train_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "539c594b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6326235058948313"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(train_y, model1.predict(train_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045886af",
   "metadata": {},
   "source": [
    "## Random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7a73a88d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV 1/5] END learning_rate=0.035293535081177003, loss=deviance, n_estimators=100;, score=(train=0.681, test=0.657) total time=   8.8s\n",
      "[CV 2/5] END learning_rate=0.035293535081177003, loss=deviance, n_estimators=100;, score=(train=0.680, test=0.668) total time=   9.0s\n",
      "[CV 3/5] END learning_rate=0.035293535081177003, loss=deviance, n_estimators=100;, score=(train=0.683, test=0.657) total time=   8.9s\n",
      "[CV 4/5] END learning_rate=0.035293535081177003, loss=deviance, n_estimators=100;, score=(train=0.677, test=0.678) total time=   8.9s\n",
      "[CV 5/5] END learning_rate=0.035293535081177003, loss=deviance, n_estimators=100;, score=(train=0.677, test=0.684) total time=   8.9s\n",
      "[CV 1/5] END learning_rate=0.11514015384658649, loss=exponential, n_estimators=100;, score=(train=0.699, test=0.668) total time=   8.8s\n",
      "[CV 2/5] END learning_rate=0.11514015384658649, loss=exponential, n_estimators=100;, score=(train=0.696, test=0.673) total time=   8.7s\n",
      "[CV 3/5] END learning_rate=0.11514015384658649, loss=exponential, n_estimators=100;, score=(train=0.699, test=0.666) total time=   8.9s\n",
      "[CV 4/5] END learning_rate=0.11514015384658649, loss=exponential, n_estimators=100;, score=(train=0.696, test=0.689) total time=   9.1s\n",
      "[CV 5/5] END learning_rate=0.11514015384658649, loss=exponential, n_estimators=100;, score=(train=0.696, test=0.691) total time=   9.5s\n",
      "[CV 1/5] END learning_rate=0.3214279965465431, loss=exponential, n_estimators=100;, score=(train=0.713, test=0.664) total time=   8.8s\n",
      "[CV 2/5] END learning_rate=0.3214279965465431, loss=exponential, n_estimators=100;, score=(train=0.711, test=0.679) total time=   8.8s\n",
      "[CV 3/5] END learning_rate=0.3214279965465431, loss=exponential, n_estimators=100;, score=(train=0.715, test=0.674) total time=   8.7s\n",
      "[CV 4/5] END learning_rate=0.3214279965465431, loss=exponential, n_estimators=100;, score=(train=0.711, test=0.693) total time=   8.8s\n",
      "[CV 5/5] END learning_rate=0.3214279965465431, loss=exponential, n_estimators=100;, score=(train=0.712, test=0.694) total time=   8.9s\n",
      "[CV 1/5] END learning_rate=0.1484993858021378, loss=exponential, n_estimators=100;, score=(train=0.702, test=0.668) total time=   8.6s\n",
      "[CV 2/5] END learning_rate=0.1484993858021378, loss=exponential, n_estimators=100;, score=(train=0.700, test=0.676) total time=   8.8s\n",
      "[CV 3/5] END learning_rate=0.1484993858021378, loss=exponential, n_estimators=100;, score=(train=0.703, test=0.670) total time=   8.8s\n",
      "[CV 4/5] END learning_rate=0.1484993858021378, loss=exponential, n_estimators=100;, score=(train=0.699, test=0.690) total time=   8.9s\n",
      "[CV 5/5] END learning_rate=0.1484993858021378, loss=exponential, n_estimators=100;, score=(train=0.700, test=0.692) total time=   8.8s\n",
      "[CV 1/5] END learning_rate=0.06449264341413151, loss=deviance, n_estimators=100;, score=(train=0.690, test=0.658) total time=   8.7s\n",
      "[CV 2/5] END learning_rate=0.06449264341413151, loss=deviance, n_estimators=100;, score=(train=0.688, test=0.670) total time=   8.9s\n",
      "[CV 3/5] END learning_rate=0.06449264341413151, loss=deviance, n_estimators=100;, score=(train=0.692, test=0.661) total time=   9.3s\n",
      "[CV 4/5] END learning_rate=0.06449264341413151, loss=deviance, n_estimators=100;, score=(train=0.688, test=0.684) total time=   9.5s\n",
      "[CV 5/5] END learning_rate=0.06449264341413151, loss=deviance, n_estimators=100;, score=(train=0.687, test=0.689) total time=   9.0s\n",
      "[CV 1/5] END learning_rate=0.07485074871210244, loss=exponential, n_estimators=100;, score=(train=0.692, test=0.662) total time=   8.9s\n",
      "[CV 2/5] END learning_rate=0.07485074871210244, loss=exponential, n_estimators=100;, score=(train=0.690, test=0.671) total time=   9.1s\n",
      "[CV 3/5] END learning_rate=0.07485074871210244, loss=exponential, n_estimators=100;, score=(train=0.694, test=0.663) total time=   9.0s\n",
      "[CV 4/5] END learning_rate=0.07485074871210244, loss=exponential, n_estimators=100;, score=(train=0.690, test=0.686) total time=   9.8s\n",
      "[CV 5/5] END learning_rate=0.07485074871210244, loss=exponential, n_estimators=100;, score=(train=0.689, test=0.689) total time=   9.4s\n",
      "[CV 1/5] END learning_rate=0.008621676640018805, loss=exponential, n_estimators=100;, score=(train=0.658, test=0.639) total time=   9.9s\n",
      "[CV 2/5] END learning_rate=0.008621676640018805, loss=exponential, n_estimators=100;, score=(train=0.655, test=0.654) total time=   9.1s\n",
      "[CV 3/5] END learning_rate=0.008621676640018805, loss=exponential, n_estimators=100;, score=(train=0.659, test=0.635) total time=   9.7s\n",
      "[CV 4/5] END learning_rate=0.008621676640018805, loss=exponential, n_estimators=100;, score=(train=0.654, test=0.659) total time=   9.5s\n",
      "[CV 5/5] END learning_rate=0.008621676640018805, loss=exponential, n_estimators=100;, score=(train=0.651, test=0.666) total time=   9.1s\n",
      "[CV 1/5] END learning_rate=0.015835446138306047, loss=deviance, n_estimators=100;, score=(train=0.667, test=0.653) total time=   9.9s\n",
      "[CV 2/5] END learning_rate=0.015835446138306047, loss=deviance, n_estimators=100;, score=(train=0.665, test=0.661) total time=  11.1s\n",
      "[CV 3/5] END learning_rate=0.015835446138306047, loss=deviance, n_estimators=100;, score=(train=0.665, test=0.640) total time=   9.8s\n",
      "[CV 4/5] END learning_rate=0.015835446138306047, loss=deviance, n_estimators=100;, score=(train=0.660, test=0.664) total time=   8.8s\n",
      "[CV 5/5] END learning_rate=0.015835446138306047, loss=deviance, n_estimators=100;, score=(train=0.659, test=0.675) total time=   8.8s\n",
      "[CV 1/5] END learning_rate=0.177197435472857, loss=deviance, n_estimators=100;, score=(train=0.705, test=0.666) total time=   8.5s\n",
      "[CV 2/5] END learning_rate=0.177197435472857, loss=deviance, n_estimators=100;, score=(train=0.702, test=0.678) total time=   8.6s\n",
      "[CV 3/5] END learning_rate=0.177197435472857, loss=deviance, n_estimators=100;, score=(train=0.706, test=0.670) total time=   8.6s\n",
      "[CV 4/5] END learning_rate=0.177197435472857, loss=deviance, n_estimators=100;, score=(train=0.703, test=0.692) total time=   8.7s\n",
      "[CV 5/5] END learning_rate=0.177197435472857, loss=deviance, n_estimators=100;, score=(train=0.702, test=0.693) total time=   8.8s\n",
      "[CV 1/5] END learning_rate=0.02523299946692438, loss=deviance, n_estimators=100;, score=(train=0.675, test=0.655) total time=   8.7s\n",
      "[CV 2/5] END learning_rate=0.02523299946692438, loss=deviance, n_estimators=100;, score=(train=0.676, test=0.667) total time=   8.7s\n",
      "[CV 3/5] END learning_rate=0.02523299946692438, loss=deviance, n_estimators=100;, score=(train=0.677, test=0.653) total time=   8.7s\n",
      "[CV 4/5] END learning_rate=0.02523299946692438, loss=deviance, n_estimators=100;, score=(train=0.671, test=0.674) total time=   8.7s\n",
      "[CV 5/5] END learning_rate=0.02523299946692438, loss=deviance, n_estimators=100;, score=(train=0.670, test=0.681) total time=   8.9s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.3214279965465431,\n",
       " 'loss': 'exponential',\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'loss':('deviance', 'exponential'), 'learning_rate':scipy.stats.expon(scale=.1),\n",
    "              'n_estimators':[100]}\n",
    "model_temp = GradientBoostingClassifier()\n",
    "RS = RandomizedSearchCV(model_temp, parameters, scoring = 'roc_auc', return_train_score=True, verbose=3)\n",
    "RS.fit(train_X, train_y)\n",
    "RS.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8a4a601f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(learning_rate=0.3214279965465431, loss='exponential')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_RS = GradientBoostingClassifier(learning_rate=0.3214279965465431, loss='exponential', n_estimators=100)\n",
    "model_RS.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9e0d9de8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6425857235294186"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(train_y, model_RS.predict(train_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6fdd8e20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6490841594256109"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(train_y, model_RS.predict(train_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c19634",
   "metadata": {},
   "source": [
    "## Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "680cdeee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "[CV 1/5] END learning_rate=0.01, loss=deviance, n_estimators=10;, score=(train=0.642, test=0.622) total time=   1.0s\n",
      "[CV 2/5] END learning_rate=0.01, loss=deviance, n_estimators=10;, score=(train=0.642, test=0.648) total time=   1.1s\n",
      "[CV 3/5] END learning_rate=0.01, loss=deviance, n_estimators=10;, score=(train=0.647, test=0.629) total time=   1.0s\n",
      "[CV 4/5] END learning_rate=0.01, loss=deviance, n_estimators=10;, score=(train=0.643, test=0.648) total time=   1.0s\n",
      "[CV 5/5] END learning_rate=0.01, loss=deviance, n_estimators=10;, score=(train=0.642, test=0.655) total time=   1.0s\n",
      "[CV 1/5] END learning_rate=0.01, loss=deviance, n_estimators=100;, score=(train=0.658, test=0.640) total time=  10.8s\n",
      "[CV 2/5] END learning_rate=0.01, loss=deviance, n_estimators=100;, score=(train=0.656, test=0.654) total time=  10.6s\n",
      "[CV 3/5] END learning_rate=0.01, loss=deviance, n_estimators=100;, score=(train=0.660, test=0.635) total time=  10.5s\n",
      "[CV 4/5] END learning_rate=0.01, loss=deviance, n_estimators=100;, score=(train=0.655, test=0.659) total time=  10.3s\n",
      "[CV 5/5] END learning_rate=0.01, loss=deviance, n_estimators=100;, score=(train=0.652, test=0.669) total time=  10.3s\n",
      "[CV 1/5] END learning_rate=0.01, loss=deviance, n_estimators=200;, score=(train=0.671, test=0.654) total time=  20.9s\n",
      "[CV 2/5] END learning_rate=0.01, loss=deviance, n_estimators=200;, score=(train=0.670, test=0.664) total time=  21.1s\n",
      "[CV 3/5] END learning_rate=0.01, loss=deviance, n_estimators=200;, score=(train=0.670, test=0.646) total time=  20.8s\n",
      "[CV 4/5] END learning_rate=0.01, loss=deviance, n_estimators=200;, score=(train=0.665, test=0.669) total time=  21.2s\n",
      "[CV 5/5] END learning_rate=0.01, loss=deviance, n_estimators=200;, score=(train=0.665, test=0.677) total time=  21.0s\n",
      "[CV 1/5] END learning_rate=0.01, loss=exponential, n_estimators=10;, score=(train=0.642, test=0.622) total time=   0.9s\n",
      "[CV 2/5] END learning_rate=0.01, loss=exponential, n_estimators=10;, score=(train=0.642, test=0.648) total time=   1.1s\n",
      "[CV 3/5] END learning_rate=0.01, loss=exponential, n_estimators=10;, score=(train=0.647, test=0.629) total time=   1.0s\n",
      "[CV 4/5] END learning_rate=0.01, loss=exponential, n_estimators=10;, score=(train=0.643, test=0.648) total time=   1.0s\n",
      "[CV 5/5] END learning_rate=0.01, loss=exponential, n_estimators=10;, score=(train=0.642, test=0.655) total time=   1.0s\n",
      "[CV 1/5] END learning_rate=0.01, loss=exponential, n_estimators=100;, score=(train=0.658, test=0.641) total time=  10.2s\n",
      "[CV 2/5] END learning_rate=0.01, loss=exponential, n_estimators=100;, score=(train=0.656, test=0.655) total time=  10.3s\n",
      "[CV 3/5] END learning_rate=0.01, loss=exponential, n_estimators=100;, score=(train=0.660, test=0.635) total time=  10.1s\n",
      "[CV 4/5] END learning_rate=0.01, loss=exponential, n_estimators=100;, score=(train=0.655, test=0.659) total time=  10.3s\n",
      "[CV 5/5] END learning_rate=0.01, loss=exponential, n_estimators=100;, score=(train=0.652, test=0.669) total time=  10.4s\n",
      "[CV 1/5] END learning_rate=0.01, loss=exponential, n_estimators=200;, score=(train=0.672, test=0.655) total time=  21.0s\n",
      "[CV 2/5] END learning_rate=0.01, loss=exponential, n_estimators=200;, score=(train=0.670, test=0.664) total time=  20.7s\n",
      "[CV 3/5] END learning_rate=0.01, loss=exponential, n_estimators=200;, score=(train=0.671, test=0.647) total time=  21.2s\n",
      "[CV 4/5] END learning_rate=0.01, loss=exponential, n_estimators=200;, score=(train=0.665, test=0.669) total time=  20.6s\n",
      "[CV 5/5] END learning_rate=0.01, loss=exponential, n_estimators=200;, score=(train=0.665, test=0.677) total time=  20.9s\n",
      "[CV 1/5] END learning_rate=0.1, loss=deviance, n_estimators=10;, score=(train=0.658, test=0.641) total time=   1.0s\n",
      "[CV 2/5] END learning_rate=0.1, loss=deviance, n_estimators=10;, score=(train=0.655, test=0.657) total time=   1.1s\n",
      "[CV 3/5] END learning_rate=0.1, loss=deviance, n_estimators=10;, score=(train=0.659, test=0.635) total time=   1.0s\n",
      "[CV 4/5] END learning_rate=0.1, loss=deviance, n_estimators=10;, score=(train=0.654, test=0.657) total time=   1.0s\n",
      "[CV 5/5] END learning_rate=0.1, loss=deviance, n_estimators=10;, score=(train=0.651, test=0.667) total time=   1.0s\n",
      "[CV 1/5] END learning_rate=0.1, loss=deviance, n_estimators=100;, score=(train=0.696, test=0.664) total time=  10.6s\n",
      "[CV 2/5] END learning_rate=0.1, loss=deviance, n_estimators=100;, score=(train=0.694, test=0.673) total time=  10.2s\n",
      "[CV 3/5] END learning_rate=0.1, loss=deviance, n_estimators=100;, score=(train=0.698, test=0.665) total time=  10.3s\n",
      "[CV 4/5] END learning_rate=0.1, loss=deviance, n_estimators=100;, score=(train=0.694, test=0.687) total time=  10.3s\n",
      "[CV 5/5] END learning_rate=0.1, loss=deviance, n_estimators=100;, score=(train=0.694, test=0.691) total time=  10.4s\n",
      "[CV 1/5] END learning_rate=0.1, loss=deviance, n_estimators=200;, score=(train=0.706, test=0.669) total time=  20.6s\n",
      "[CV 2/5] END learning_rate=0.1, loss=deviance, n_estimators=200;, score=(train=0.704, test=0.677) total time=  21.0s\n",
      "[CV 3/5] END learning_rate=0.1, loss=deviance, n_estimators=200;, score=(train=0.708, test=0.671) total time=  20.6s\n",
      "[CV 4/5] END learning_rate=0.1, loss=deviance, n_estimators=200;, score=(train=0.705, test=0.693) total time=  20.8s\n",
      "[CV 5/5] END learning_rate=0.1, loss=deviance, n_estimators=200;, score=(train=0.704, test=0.694) total time=  20.8s\n",
      "[CV 1/5] END learning_rate=0.1, loss=exponential, n_estimators=10;, score=(train=0.658, test=0.641) total time=   1.0s\n",
      "[CV 2/5] END learning_rate=0.1, loss=exponential, n_estimators=10;, score=(train=0.655, test=0.657) total time=   1.0s\n",
      "[CV 3/5] END learning_rate=0.1, loss=exponential, n_estimators=10;, score=(train=0.660, test=0.636) total time=   1.0s\n",
      "[CV 4/5] END learning_rate=0.1, loss=exponential, n_estimators=10;, score=(train=0.654, test=0.657) total time=   1.0s\n",
      "[CV 5/5] END learning_rate=0.1, loss=exponential, n_estimators=10;, score=(train=0.651, test=0.667) total time=   1.0s\n",
      "[CV 1/5] END learning_rate=0.1, loss=exponential, n_estimators=100;, score=(train=0.696, test=0.663) total time=  10.5s\n",
      "[CV 2/5] END learning_rate=0.1, loss=exponential, n_estimators=100;, score=(train=0.694, test=0.673) total time=  10.5s\n",
      "[CV 3/5] END learning_rate=0.1, loss=exponential, n_estimators=100;, score=(train=0.698, test=0.665) total time=  10.6s\n",
      "[CV 4/5] END learning_rate=0.1, loss=exponential, n_estimators=100;, score=(train=0.694, test=0.687) total time=  10.7s\n",
      "[CV 5/5] END learning_rate=0.1, loss=exponential, n_estimators=100;, score=(train=0.693, test=0.691) total time=  10.6s\n",
      "[CV 1/5] END learning_rate=0.1, loss=exponential, n_estimators=200;, score=(train=0.706, test=0.669) total time=  20.4s\n",
      "[CV 2/5] END learning_rate=0.1, loss=exponential, n_estimators=200;, score=(train=0.704, test=0.678) total time=  20.4s\n",
      "[CV 3/5] END learning_rate=0.1, loss=exponential, n_estimators=200;, score=(train=0.707, test=0.671) total time=  21.3s\n",
      "[CV 4/5] END learning_rate=0.1, loss=exponential, n_estimators=200;, score=(train=0.704, test=0.692) total time=  20.6s\n",
      "[CV 5/5] END learning_rate=0.1, loss=exponential, n_estimators=200;, score=(train=0.704, test=0.693) total time=  20.4s\n",
      "[CV 1/5] END learning_rate=1.0, loss=deviance, n_estimators=10;, score=(train=0.686, test=0.646) total time=   1.0s\n",
      "[CV 2/5] END learning_rate=1.0, loss=deviance, n_estimators=10;, score=(train=0.686, test=0.668) total time=   0.9s\n",
      "[CV 3/5] END learning_rate=1.0, loss=deviance, n_estimators=10;, score=(train=0.690, test=0.659) total time=   1.0s\n",
      "[CV 4/5] END learning_rate=1.0, loss=deviance, n_estimators=10;, score=(train=0.686, test=0.679) total time=   1.0s\n",
      "[CV 5/5] END learning_rate=1.0, loss=deviance, n_estimators=10;, score=(train=0.685, test=0.683) total time=   1.0s\n",
      "[CV 1/5] END learning_rate=1.0, loss=deviance, n_estimators=100;, score=(train=0.727, test=0.656) total time=  10.6s\n",
      "[CV 2/5] END learning_rate=1.0, loss=deviance, n_estimators=100;, score=(train=0.728, test=0.669) total time=  10.3s\n",
      "[CV 3/5] END learning_rate=1.0, loss=deviance, n_estimators=100;, score=(train=0.729, test=0.665) total time=  10.4s\n",
      "[CV 4/5] END learning_rate=1.0, loss=deviance, n_estimators=100;, score=(train=0.727, test=0.689) total time=  10.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END learning_rate=1.0, loss=deviance, n_estimators=100;, score=(train=0.729, test=0.682) total time=  10.3s\n",
      "[CV 1/5] END learning_rate=1.0, loss=deviance, n_estimators=200;, score=(train=0.736, test=0.652) total time=  21.2s\n",
      "[CV 2/5] END learning_rate=1.0, loss=deviance, n_estimators=200;, score=(train=0.748, test=0.666) total time=  21.2s\n",
      "[CV 3/5] END learning_rate=1.0, loss=deviance, n_estimators=200;, score=(train=0.751, test=0.659) total time=  20.6s\n",
      "[CV 4/5] END learning_rate=1.0, loss=deviance, n_estimators=200;, score=(train=0.748, test=0.686) total time=  21.0s\n",
      "[CV 5/5] END learning_rate=1.0, loss=deviance, n_estimators=200;, score=(train=0.749, test=0.674) total time=  20.4s\n",
      "[CV 1/5] END learning_rate=1.0, loss=exponential, n_estimators=10;, score=(train=0.689, test=0.655) total time=   1.0s\n",
      "[CV 2/5] END learning_rate=1.0, loss=exponential, n_estimators=10;, score=(train=0.683, test=0.667) total time=   1.0s\n",
      "[CV 3/5] END learning_rate=1.0, loss=exponential, n_estimators=10;, score=(train=0.690, test=0.656) total time=   0.9s\n",
      "[CV 4/5] END learning_rate=1.0, loss=exponential, n_estimators=10;, score=(train=0.685, test=0.680) total time=   1.0s\n",
      "[CV 5/5] END learning_rate=1.0, loss=exponential, n_estimators=10;, score=(train=0.684, test=0.683) total time=   0.9s\n",
      "[CV 1/5] END learning_rate=1.0, loss=exponential, n_estimators=100;, score=(train=0.727, test=0.655) total time=  10.1s\n",
      "[CV 2/5] END learning_rate=1.0, loss=exponential, n_estimators=100;, score=(train=0.726, test=0.667) total time=  10.4s\n",
      "[CV 3/5] END learning_rate=1.0, loss=exponential, n_estimators=100;, score=(train=0.730, test=0.670) total time=  10.4s\n",
      "[CV 4/5] END learning_rate=1.0, loss=exponential, n_estimators=100;, score=(train=0.725, test=0.689) total time=  10.8s\n",
      "[CV 5/5] END learning_rate=1.0, loss=exponential, n_estimators=100;, score=(train=0.726, test=0.684) total time=  10.2s\n",
      "[CV 1/5] END learning_rate=1.0, loss=exponential, n_estimators=200;, score=(train=0.745, test=0.649) total time=  20.7s\n",
      "[CV 2/5] END learning_rate=1.0, loss=exponential, n_estimators=200;, score=(train=0.745, test=0.660) total time=  21.0s\n",
      "[CV 3/5] END learning_rate=1.0, loss=exponential, n_estimators=200;, score=(train=0.749, test=0.665) total time=  21.0s\n",
      "[CV 4/5] END learning_rate=1.0, loss=exponential, n_estimators=200;, score=(train=0.744, test=0.685) total time=  20.4s\n",
      "[CV 5/5] END learning_rate=1.0, loss=exponential, n_estimators=200;, score=(train=0.745, test=0.679) total time=  20.9s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1, 'loss': 'deviance', 'n_estimators': 200}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'loss':('deviance', 'exponential'), 'learning_rate':[0.01, 0.1, 1.0],\n",
    "              'n_estimators':[10, 100, 200], }\n",
    "model_temp = GradientBoostingClassifier()\n",
    "GS = GridSearchCV(model_temp, parameters, scoring = 'roc_auc', return_train_score=True, verbose=3)\n",
    "GS.fit(train_X, train_y)\n",
    "GS.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a8dbbfea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(n_estimators=200)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_GS = GradientBoostingClassifier(learning_rate=0.1, loss='deviance', n_estimators=200)\n",
    "model_GS.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "89aa38a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6371257865634341"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(train_y, model_GS.predict(train_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d9b27ae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6445865459144128"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(train_y, model_GS.predict(train_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d92623",
   "metadata": {},
   "source": [
    "## Optymalizacja bayesowska"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "06025ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_spaces = {\n",
    "        'loss': ['deviance', 'exponential'],\n",
    "        'n_estimators': skopt.space.space.Integer(1, 1000),\n",
    "        'learning_rate': skopt.space.space.Real(0, 2)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7a31e641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BayesSearchCV(estimator=GradientBoostingClassifier(), n_iter=10, n_jobs=4,\n",
       "              random_state=1, scoring='roc_auc',\n",
       "              search_spaces={'learning_rate': Real(low=0, high=2, prior='uniform', transform='normalize'),\n",
       "                             'loss': ['deviance', 'exponential'],\n",
       "                             'n_estimators': Integer(low=1, high=1000, prior='uniform', transform='normalize')},\n",
       "              verbose=3)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_temp = GradientBoostingClassifier()\n",
    "opt_1 = skopt.BayesSearchCV(\n",
    "        estimator=model_temp,\n",
    "        search_spaces=search_spaces,\n",
    "        scoring='roc_auc',\n",
    "        n_jobs=4,\n",
    "        n_iter=10,\n",
    "        verbose=3,\n",
    "        random_state=1\n",
    "    )\n",
    "opt_1.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9bda90ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('learning_rate', 0.23295552444912887),\n",
       "             ('loss', 'exponential'),\n",
       "             ('n_estimators', 626)])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8df5890b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(learning_rate=0.23295552444912887,\n",
       "                           loss='exponential', n_estimators=626)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_OB = GradientBoostingClassifier(learning_rate = 0.23295552444912887, loss = 'exponential', n_estimators = 626)\n",
    "model_OB.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4b46d25b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6681935799042171"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(train_y, model_OB.predict(train_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "492b935c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6728980540937461"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(train_y, model_OB.predict(train_X))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
